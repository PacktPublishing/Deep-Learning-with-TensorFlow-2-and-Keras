{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "import  tensorflow as tf\n",
    "import  numpy as np\n",
    "from    matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "tf.random.set_seed(333)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.'), \"TensorFlow Version Below 2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train.astype(np.float32)/255., x_test.astype(np.float32)/255.\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for index in range(number):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, number, index + 1)\n",
    "    plt.imshow(x_train[index], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]*x_train.shape[2]\n",
    "hidden_dim = 512\n",
    "latent_dim = 10\n",
    "num_epochs = 80\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,dim,**kwargs):\n",
    "        h_dim = dim[0]\n",
    "        z_dim = dim[1]\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(h_dim)\n",
    "        self.fc2 = tf.keras.layers.Dense(z_dim)\n",
    "        self.fc3 = tf.keras.layers.Dense(z_dim)\n",
    "\n",
    "        self.fc4 = tf.keras.layers.Dense(h_dim)\n",
    "        self.fc5 = tf.keras.layers.Dense(image_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = tf.nn.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = tf.exp(log_var * 0.5)\n",
    "        eps = tf.random.normal(std.shape)\n",
    "\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode_logits(self, z):\n",
    "        h = tf.nn.relu(self.fc4(z))\n",
    "        return self.fc5(h)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return tf.nn.sigmoid(self.decode_logits(z))\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        mu, log_var = self.encode(inputs)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconstructed_logits = self.decode_logits(z)\n",
    "\n",
    "        return x_reconstructed_logits, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  5130      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  5130      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  5632      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  402192    \n",
      "=================================================================\n",
      "Total params: 820,004\n",
      "Trainable params: 820,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VAE([hidden_dim, latent_dim])\n",
    "model.build(input_shape=(4, image_size))\n",
    "model.summary()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/am/anaconda3/envs/new_tf/lib/python3.6/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch[1/80], Step [50/600], Reconst Loss: 294.8600, KL Div: 14.0198\n",
      "Epoch[1/80], Step [100/600], Reconst Loss: 291.6082, KL Div: 14.1258\n",
      "Epoch[1/80], Step [150/600], Reconst Loss: 252.8786, KL Div: 14.9382\n",
      "Epoch[1/80], Step [200/600], Reconst Loss: 255.8645, KL Div: 12.9271\n",
      "Epoch[1/80], Step [250/600], Reconst Loss: 254.9781, KL Div: 14.3380\n",
      "Epoch[1/80], Step [300/600], Reconst Loss: 258.4062, KL Div: 14.7392\n",
      "Epoch[1/80], Step [350/600], Reconst Loss: 244.1019, KL Div: 15.0542\n",
      "Epoch[1/80], Step [400/600], Reconst Loss: 240.9099, KL Div: 13.8287\n",
      "Epoch[1/80], Step [450/600], Reconst Loss: 240.4739, KL Div: 13.7020\n",
      "Epoch[1/80], Step [500/600], Reconst Loss: 243.7411, KL Div: 13.7590\n",
      "Epoch[1/80], Step [550/600], Reconst Loss: 240.6016, KL Div: 14.1020\n",
      "Epoch[1/80], Step [600/600], Reconst Loss: 223.1697, KL Div: 15.4757\n",
      "Epoch[2/80], Step [50/600], Reconst Loss: 244.8813, KL Div: 14.9065\n",
      "Epoch[2/80], Step [100/600], Reconst Loss: 229.3795, KL Div: 14.3339\n",
      "Epoch[2/80], Step [150/600], Reconst Loss: 228.9993, KL Div: 15.2811\n",
      "Epoch[2/80], Step [200/600], Reconst Loss: 233.6124, KL Div: 14.9415\n",
      "Epoch[2/80], Step [250/600], Reconst Loss: 252.0581, KL Div: 14.7064\n",
      "Epoch[2/80], Step [300/600], Reconst Loss: 234.1520, KL Div: 14.0307\n",
      "Epoch[2/80], Step [350/600], Reconst Loss: 226.0999, KL Div: 14.9748\n",
      "Epoch[2/80], Step [400/600], Reconst Loss: 238.7061, KL Div: 14.8830\n",
      "Epoch[2/80], Step [450/600], Reconst Loss: 243.3348, KL Div: 15.7993\n",
      "Epoch[2/80], Step [500/600], Reconst Loss: 224.9654, KL Div: 16.0518\n",
      "Epoch[2/80], Step [550/600], Reconst Loss: 236.1470, KL Div: 15.4662\n",
      "Epoch[2/80], Step [600/600], Reconst Loss: 238.6007, KL Div: 15.0486\n",
      "Epoch[3/80], Step [50/600], Reconst Loss: 223.1263, KL Div: 15.2558\n",
      "Epoch[3/80], Step [100/600], Reconst Loss: 236.2603, KL Div: 15.3218\n",
      "Epoch[3/80], Step [150/600], Reconst Loss: 231.8307, KL Div: 14.3006\n",
      "Epoch[3/80], Step [200/600], Reconst Loss: 228.4309, KL Div: 14.8245\n",
      "Epoch[3/80], Step [250/600], Reconst Loss: 236.4471, KL Div: 14.7226\n",
      "Epoch[3/80], Step [300/600], Reconst Loss: 228.2165, KL Div: 14.5975\n",
      "Epoch[3/80], Step [350/600], Reconst Loss: 235.9454, KL Div: 15.7540\n",
      "Epoch[3/80], Step [400/600], Reconst Loss: 240.4326, KL Div: 14.8957\n",
      "Epoch[3/80], Step [450/600], Reconst Loss: 219.5821, KL Div: 14.9204\n",
      "Epoch[3/80], Step [500/600], Reconst Loss: 239.9554, KL Div: 15.5976\n",
      "Epoch[3/80], Step [550/600], Reconst Loss: 250.5829, KL Div: 15.2192\n",
      "Epoch[3/80], Step [600/600], Reconst Loss: 224.0628, KL Div: 15.3955\n",
      "Epoch[4/80], Step [50/600], Reconst Loss: 223.2348, KL Div: 15.6836\n",
      "Epoch[4/80], Step [100/600], Reconst Loss: 221.5105, KL Div: 15.9767\n",
      "Epoch[4/80], Step [150/600], Reconst Loss: 222.4259, KL Div: 16.2832\n",
      "Epoch[4/80], Step [200/600], Reconst Loss: 229.8865, KL Div: 14.8377\n",
      "Epoch[4/80], Step [250/600], Reconst Loss: 236.0214, KL Div: 15.5693\n",
      "Epoch[4/80], Step [300/600], Reconst Loss: 234.2791, KL Div: 15.7786\n",
      "Epoch[4/80], Step [350/600], Reconst Loss: 225.1683, KL Div: 14.5457\n",
      "Epoch[4/80], Step [400/600], Reconst Loss: 216.0263, KL Div: 15.5687\n",
      "Epoch[4/80], Step [450/600], Reconst Loss: 222.4077, KL Div: 15.2247\n",
      "Epoch[4/80], Step [500/600], Reconst Loss: 238.7264, KL Div: 15.2233\n",
      "Epoch[4/80], Step [550/600], Reconst Loss: 229.6419, KL Div: 15.1415\n",
      "Epoch[4/80], Step [600/600], Reconst Loss: 240.9477, KL Div: 15.9253\n",
      "Epoch[5/80], Step [50/600], Reconst Loss: 232.4624, KL Div: 16.1482\n",
      "Epoch[5/80], Step [100/600], Reconst Loss: 225.5408, KL Div: 15.6923\n",
      "Epoch[5/80], Step [150/600], Reconst Loss: 240.3142, KL Div: 15.0500\n",
      "Epoch[5/80], Step [200/600], Reconst Loss: 238.9924, KL Div: 14.8965\n",
      "Epoch[5/80], Step [250/600], Reconst Loss: 228.2729, KL Div: 15.5563\n",
      "Epoch[5/80], Step [300/600], Reconst Loss: 228.1653, KL Div: 15.2176\n",
      "Epoch[5/80], Step [350/600], Reconst Loss: 225.9763, KL Div: 16.3616\n",
      "Epoch[5/80], Step [400/600], Reconst Loss: 235.0809, KL Div: 15.3984\n",
      "Epoch[5/80], Step [450/600], Reconst Loss: 224.3749, KL Div: 15.5072\n",
      "Epoch[5/80], Step [500/600], Reconst Loss: 229.5713, KL Div: 14.8366\n",
      "Epoch[5/80], Step [550/600], Reconst Loss: 219.7494, KL Div: 14.6823\n",
      "Epoch[5/80], Step [600/600], Reconst Loss: 231.8100, KL Div: 15.4151\n",
      "Epoch[6/80], Step [50/600], Reconst Loss: 230.4247, KL Div: 15.8821\n",
      "Epoch[6/80], Step [100/600], Reconst Loss: 237.4187, KL Div: 14.9983\n",
      "Epoch[6/80], Step [150/600], Reconst Loss: 231.7842, KL Div: 15.3438\n",
      "Epoch[6/80], Step [200/600], Reconst Loss: 229.7288, KL Div: 15.2951\n",
      "Epoch[6/80], Step [250/600], Reconst Loss: 220.7977, KL Div: 14.9554\n",
      "Epoch[6/80], Step [300/600], Reconst Loss: 227.9247, KL Div: 15.5167\n",
      "Epoch[6/80], Step [350/600], Reconst Loss: 233.8160, KL Div: 15.2479\n",
      "Epoch[6/80], Step [400/600], Reconst Loss: 225.9467, KL Div: 16.0912\n",
      "Epoch[6/80], Step [450/600], Reconst Loss: 234.4911, KL Div: 15.4327\n",
      "Epoch[6/80], Step [500/600], Reconst Loss: 236.3823, KL Div: 15.6023\n",
      "Epoch[6/80], Step [550/600], Reconst Loss: 226.8154, KL Div: 14.9969\n",
      "Epoch[6/80], Step [600/600], Reconst Loss: 221.1820, KL Div: 15.6934\n",
      "Epoch[7/80], Step [50/600], Reconst Loss: 236.8059, KL Div: 15.6820\n",
      "Epoch[7/80], Step [100/600], Reconst Loss: 239.1294, KL Div: 15.6774\n",
      "Epoch[7/80], Step [150/600], Reconst Loss: 243.6043, KL Div: 16.0134\n",
      "Epoch[7/80], Step [200/600], Reconst Loss: 223.2675, KL Div: 14.9912\n",
      "Epoch[7/80], Step [250/600], Reconst Loss: 226.5360, KL Div: 15.7397\n",
      "Epoch[7/80], Step [300/600], Reconst Loss: 216.0893, KL Div: 15.1519\n",
      "Epoch[7/80], Step [350/600], Reconst Loss: 218.6844, KL Div: 15.2418\n",
      "Epoch[7/80], Step [400/600], Reconst Loss: 233.8068, KL Div: 14.8473\n",
      "Epoch[7/80], Step [450/600], Reconst Loss: 227.8113, KL Div: 14.7656\n",
      "Epoch[7/80], Step [500/600], Reconst Loss: 236.3686, KL Div: 14.2611\n",
      "Epoch[7/80], Step [550/600], Reconst Loss: 210.2136, KL Div: 16.4265\n",
      "Epoch[7/80], Step [600/600], Reconst Loss: 230.6586, KL Div: 15.4612\n",
      "Epoch[8/80], Step [50/600], Reconst Loss: 229.0239, KL Div: 15.6552\n",
      "Epoch[8/80], Step [100/600], Reconst Loss: 229.5285, KL Div: 15.5075\n",
      "Epoch[8/80], Step [150/600], Reconst Loss: 233.0718, KL Div: 14.5289\n",
      "Epoch[8/80], Step [200/600], Reconst Loss: 226.5691, KL Div: 15.8363\n",
      "Epoch[8/80], Step [250/600], Reconst Loss: 229.4637, KL Div: 15.3250\n",
      "Epoch[8/80], Step [300/600], Reconst Loss: 228.8260, KL Div: 15.6019\n",
      "Epoch[8/80], Step [350/600], Reconst Loss: 233.3806, KL Div: 15.9641\n",
      "Epoch[8/80], Step [400/600], Reconst Loss: 231.7590, KL Div: 15.0985\n",
      "Epoch[8/80], Step [450/600], Reconst Loss: 231.3959, KL Div: 15.2063\n",
      "Epoch[8/80], Step [500/600], Reconst Loss: 227.4835, KL Div: 15.7287\n",
      "Epoch[8/80], Step [550/600], Reconst Loss: 234.2148, KL Div: 15.6143\n",
      "Epoch[8/80], Step [600/600], Reconst Loss: 238.7637, KL Div: 14.9202\n",
      "Epoch[9/80], Step [50/600], Reconst Loss: 215.1844, KL Div: 15.4535\n",
      "Epoch[9/80], Step [100/600], Reconst Loss: 220.7312, KL Div: 15.0521\n",
      "Epoch[9/80], Step [150/600], Reconst Loss: 226.4191, KL Div: 15.8197\n",
      "Epoch[9/80], Step [200/600], Reconst Loss: 237.5036, KL Div: 15.6153\n",
      "Epoch[9/80], Step [250/600], Reconst Loss: 231.6457, KL Div: 15.0790\n",
      "Epoch[9/80], Step [300/600], Reconst Loss: 234.1122, KL Div: 14.6786\n",
      "Epoch[9/80], Step [350/600], Reconst Loss: 220.0982, KL Div: 15.6565\n",
      "Epoch[9/80], Step [400/600], Reconst Loss: 238.8478, KL Div: 15.1344\n",
      "Epoch[9/80], Step [450/600], Reconst Loss: 227.7007, KL Div: 15.7715\n",
      "Epoch[9/80], Step [500/600], Reconst Loss: 238.6784, KL Div: 15.3962\n",
      "Epoch[9/80], Step [550/600], Reconst Loss: 234.7060, KL Div: 15.4746\n",
      "Epoch[9/80], Step [600/600], Reconst Loss: 233.7919, KL Div: 14.0827\n",
      "Epoch[10/80], Step [50/600], Reconst Loss: 232.2358, KL Div: 15.4034\n",
      "Epoch[10/80], Step [100/600], Reconst Loss: 231.3960, KL Div: 15.4303\n",
      "Epoch[10/80], Step [150/600], Reconst Loss: 231.9851, KL Div: 15.2089\n",
      "Epoch[10/80], Step [200/600], Reconst Loss: 217.6243, KL Div: 15.7084\n",
      "Epoch[10/80], Step [250/600], Reconst Loss: 237.4964, KL Div: 14.6597\n",
      "Epoch[10/80], Step [300/600], Reconst Loss: 216.3875, KL Div: 14.6167\n",
      "Epoch[10/80], Step [350/600], Reconst Loss: 233.4446, KL Div: 15.2790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/80], Step [400/600], Reconst Loss: 225.7885, KL Div: 15.9701\n",
      "Epoch[10/80], Step [450/600], Reconst Loss: 226.3832, KL Div: 16.0241\n",
      "Epoch[10/80], Step [500/600], Reconst Loss: 233.2399, KL Div: 15.0439\n",
      "Epoch[10/80], Step [550/600], Reconst Loss: 234.0270, KL Div: 15.9009\n",
      "Epoch[10/80], Step [600/600], Reconst Loss: 224.0077, KL Div: 15.4706\n",
      "Epoch[11/80], Step [50/600], Reconst Loss: 230.5562, KL Div: 15.1643\n",
      "Epoch[11/80], Step [100/600], Reconst Loss: 228.2859, KL Div: 14.7181\n",
      "Epoch[11/80], Step [150/600], Reconst Loss: 230.2280, KL Div: 15.4212\n",
      "Epoch[11/80], Step [200/600], Reconst Loss: 227.0472, KL Div: 14.8851\n",
      "Epoch[11/80], Step [250/600], Reconst Loss: 231.6181, KL Div: 15.3818\n",
      "Epoch[11/80], Step [300/600], Reconst Loss: 225.6627, KL Div: 14.2350\n",
      "Epoch[11/80], Step [350/600], Reconst Loss: 227.4138, KL Div: 15.3015\n",
      "Epoch[11/80], Step [400/600], Reconst Loss: 222.6382, KL Div: 14.5104\n",
      "Epoch[11/80], Step [450/600], Reconst Loss: 227.4146, KL Div: 15.5325\n",
      "Epoch[11/80], Step [500/600], Reconst Loss: 233.5160, KL Div: 15.3542\n",
      "Epoch[11/80], Step [550/600], Reconst Loss: 236.9245, KL Div: 14.7104\n",
      "Epoch[11/80], Step [600/600], Reconst Loss: 219.8350, KL Div: 15.4964\n",
      "Epoch[12/80], Step [50/600], Reconst Loss: 239.3501, KL Div: 15.8840\n",
      "Epoch[12/80], Step [100/600], Reconst Loss: 219.4734, KL Div: 15.0462\n",
      "Epoch[12/80], Step [150/600], Reconst Loss: 229.0167, KL Div: 15.5372\n",
      "Epoch[12/80], Step [200/600], Reconst Loss: 240.9793, KL Div: 16.0863\n",
      "Epoch[12/80], Step [250/600], Reconst Loss: 218.6577, KL Div: 15.4533\n",
      "Epoch[12/80], Step [300/600], Reconst Loss: 227.4334, KL Div: 14.8309\n",
      "Epoch[12/80], Step [350/600], Reconst Loss: 225.2284, KL Div: 14.9286\n",
      "Epoch[12/80], Step [400/600], Reconst Loss: 219.4045, KL Div: 15.9298\n",
      "Epoch[12/80], Step [450/600], Reconst Loss: 211.7712, KL Div: 15.4150\n",
      "Epoch[12/80], Step [500/600], Reconst Loss: 233.7561, KL Div: 14.9751\n",
      "Epoch[12/80], Step [550/600], Reconst Loss: 222.4669, KL Div: 15.5872\n",
      "Epoch[12/80], Step [600/600], Reconst Loss: 239.5462, KL Div: 15.6953\n",
      "Epoch[13/80], Step [50/600], Reconst Loss: 209.9504, KL Div: 15.2006\n",
      "Epoch[13/80], Step [100/600], Reconst Loss: 224.1635, KL Div: 15.4421\n",
      "Epoch[13/80], Step [150/600], Reconst Loss: 221.3048, KL Div: 15.0607\n",
      "Epoch[13/80], Step [200/600], Reconst Loss: 230.1034, KL Div: 16.1335\n",
      "Epoch[13/80], Step [250/600], Reconst Loss: 230.1999, KL Div: 15.2269\n",
      "Epoch[13/80], Step [300/600], Reconst Loss: 230.9740, KL Div: 16.3825\n",
      "Epoch[13/80], Step [350/600], Reconst Loss: 231.5140, KL Div: 14.8972\n",
      "Epoch[13/80], Step [400/600], Reconst Loss: 221.9798, KL Div: 15.3679\n",
      "Epoch[13/80], Step [450/600], Reconst Loss: 223.9673, KL Div: 15.7432\n",
      "Epoch[13/80], Step [500/600], Reconst Loss: 229.8135, KL Div: 15.0597\n",
      "Epoch[13/80], Step [550/600], Reconst Loss: 217.5131, KL Div: 14.8954\n",
      "Epoch[13/80], Step [600/600], Reconst Loss: 226.9720, KL Div: 15.6104\n",
      "Epoch[14/80], Step [50/600], Reconst Loss: 227.5638, KL Div: 15.1914\n",
      "Epoch[14/80], Step [100/600], Reconst Loss: 227.7957, KL Div: 15.3580\n",
      "Epoch[14/80], Step [150/600], Reconst Loss: 233.8316, KL Div: 15.8318\n",
      "Epoch[14/80], Step [200/600], Reconst Loss: 242.7940, KL Div: 15.8167\n",
      "Epoch[14/80], Step [250/600], Reconst Loss: 226.1380, KL Div: 16.1840\n",
      "Epoch[14/80], Step [300/600], Reconst Loss: 225.3638, KL Div: 15.9694\n",
      "Epoch[14/80], Step [350/600], Reconst Loss: 235.7704, KL Div: 16.0837\n",
      "Epoch[14/80], Step [400/600], Reconst Loss: 217.2631, KL Div: 15.0822\n",
      "Epoch[14/80], Step [450/600], Reconst Loss: 222.7621, KL Div: 15.0753\n",
      "Epoch[14/80], Step [500/600], Reconst Loss: 235.3924, KL Div: 16.2793\n",
      "Epoch[14/80], Step [550/600], Reconst Loss: 214.2862, KL Div: 15.9454\n",
      "Epoch[14/80], Step [600/600], Reconst Loss: 225.5793, KL Div: 16.6727\n",
      "Epoch[15/80], Step [50/600], Reconst Loss: 228.9980, KL Div: 15.5730\n",
      "Epoch[15/80], Step [100/600], Reconst Loss: 219.2359, KL Div: 15.6125\n",
      "Epoch[15/80], Step [150/600], Reconst Loss: 225.6227, KL Div: 14.6715\n",
      "Epoch[15/80], Step [200/600], Reconst Loss: 232.8998, KL Div: 15.2155\n",
      "Epoch[15/80], Step [250/600], Reconst Loss: 222.5247, KL Div: 15.3693\n",
      "Epoch[15/80], Step [300/600], Reconst Loss: 226.8339, KL Div: 15.4772\n",
      "Epoch[15/80], Step [350/600], Reconst Loss: 228.4713, KL Div: 15.4603\n",
      "Epoch[15/80], Step [400/600], Reconst Loss: 224.1424, KL Div: 15.7828\n",
      "Epoch[15/80], Step [450/600], Reconst Loss: 223.8216, KL Div: 16.0648\n",
      "Epoch[15/80], Step [500/600], Reconst Loss: 220.1283, KL Div: 15.2216\n",
      "Epoch[15/80], Step [550/600], Reconst Loss: 230.2528, KL Div: 15.6233\n",
      "Epoch[15/80], Step [600/600], Reconst Loss: 228.1707, KL Div: 15.7281\n",
      "Epoch[16/80], Step [50/600], Reconst Loss: 226.6670, KL Div: 14.7585\n",
      "Epoch[16/80], Step [100/600], Reconst Loss: 224.7596, KL Div: 15.7063\n",
      "Epoch[16/80], Step [150/600], Reconst Loss: 215.8262, KL Div: 14.9696\n",
      "Epoch[16/80], Step [200/600], Reconst Loss: 217.2526, KL Div: 14.9060\n",
      "Epoch[16/80], Step [250/600], Reconst Loss: 220.4832, KL Div: 15.6750\n",
      "Epoch[16/80], Step [300/600], Reconst Loss: 232.9703, KL Div: 14.2853\n",
      "Epoch[16/80], Step [350/600], Reconst Loss: 218.5165, KL Div: 14.7416\n",
      "Epoch[16/80], Step [400/600], Reconst Loss: 233.0050, KL Div: 15.5858\n",
      "Epoch[16/80], Step [450/600], Reconst Loss: 232.5777, KL Div: 16.6043\n",
      "Epoch[16/80], Step [500/600], Reconst Loss: 231.5262, KL Div: 15.1749\n",
      "Epoch[16/80], Step [550/600], Reconst Loss: 229.5903, KL Div: 15.4140\n",
      "Epoch[16/80], Step [600/600], Reconst Loss: 224.8927, KL Div: 15.1173\n",
      "Epoch[17/80], Step [50/600], Reconst Loss: 229.2460, KL Div: 16.0547\n",
      "Epoch[17/80], Step [100/600], Reconst Loss: 216.0616, KL Div: 14.8423\n",
      "Epoch[17/80], Step [150/600], Reconst Loss: 235.0391, KL Div: 15.6788\n",
      "Epoch[17/80], Step [200/600], Reconst Loss: 223.2039, KL Div: 14.3916\n",
      "Epoch[17/80], Step [250/600], Reconst Loss: 224.5009, KL Div: 15.0135\n",
      "Epoch[17/80], Step [300/600], Reconst Loss: 233.0919, KL Div: 15.2016\n",
      "Epoch[17/80], Step [350/600], Reconst Loss: 224.9230, KL Div: 15.4841\n",
      "Epoch[17/80], Step [400/600], Reconst Loss: 230.3004, KL Div: 15.3822\n",
      "Epoch[17/80], Step [450/600], Reconst Loss: 238.6610, KL Div: 15.8432\n",
      "Epoch[17/80], Step [500/600], Reconst Loss: 237.0184, KL Div: 14.7140\n",
      "Epoch[17/80], Step [550/600], Reconst Loss: 228.4704, KL Div: 15.2482\n",
      "Epoch[17/80], Step [600/600], Reconst Loss: 224.5635, KL Div: 15.7486\n",
      "Epoch[18/80], Step [50/600], Reconst Loss: 222.3739, KL Div: 15.2918\n",
      "Epoch[18/80], Step [100/600], Reconst Loss: 229.8221, KL Div: 15.9641\n",
      "Epoch[18/80], Step [150/600], Reconst Loss: 225.0960, KL Div: 15.0338\n",
      "Epoch[18/80], Step [200/600], Reconst Loss: 221.8024, KL Div: 14.9596\n",
      "Epoch[18/80], Step [250/600], Reconst Loss: 219.1720, KL Div: 15.6363\n",
      "Epoch[18/80], Step [300/600], Reconst Loss: 225.7148, KL Div: 15.0343\n",
      "Epoch[18/80], Step [350/600], Reconst Loss: 229.6409, KL Div: 15.2436\n",
      "Epoch[18/80], Step [400/600], Reconst Loss: 223.5201, KL Div: 15.5689\n",
      "Epoch[18/80], Step [450/600], Reconst Loss: 221.5166, KL Div: 16.1486\n",
      "Epoch[18/80], Step [500/600], Reconst Loss: 228.8109, KL Div: 15.6095\n",
      "Epoch[18/80], Step [550/600], Reconst Loss: 244.2287, KL Div: 16.0793\n",
      "Epoch[18/80], Step [600/600], Reconst Loss: 226.4631, KL Div: 15.8842\n",
      "Epoch[19/80], Step [50/600], Reconst Loss: 226.4996, KL Div: 14.9706\n",
      "Epoch[19/80], Step [100/600], Reconst Loss: 227.1344, KL Div: 16.1504\n",
      "Epoch[19/80], Step [150/600], Reconst Loss: 209.8552, KL Div: 14.9473\n",
      "Epoch[19/80], Step [200/600], Reconst Loss: 223.5012, KL Div: 14.1602\n",
      "Epoch[19/80], Step [250/600], Reconst Loss: 224.2277, KL Div: 15.1170\n",
      "Epoch[19/80], Step [300/600], Reconst Loss: 235.2884, KL Div: 15.1405\n",
      "Epoch[19/80], Step [350/600], Reconst Loss: 213.0228, KL Div: 15.3057\n",
      "Epoch[19/80], Step [400/600], Reconst Loss: 231.7007, KL Div: 16.1979\n",
      "Epoch[19/80], Step [450/600], Reconst Loss: 223.7904, KL Div: 15.2315\n",
      "Epoch[19/80], Step [500/600], Reconst Loss: 227.3508, KL Div: 15.6410\n",
      "Epoch[19/80], Step [550/600], Reconst Loss: 236.2312, KL Div: 15.4073\n",
      "Epoch[19/80], Step [600/600], Reconst Loss: 233.7026, KL Div: 15.7773\n",
      "Epoch[20/80], Step [50/600], Reconst Loss: 230.5726, KL Div: 15.6658\n",
      "Epoch[20/80], Step [100/600], Reconst Loss: 217.4411, KL Div: 15.3378\n",
      "Epoch[20/80], Step [150/600], Reconst Loss: 221.8147, KL Div: 15.7836\n",
      "Epoch[20/80], Step [200/600], Reconst Loss: 238.9701, KL Div: 14.8240\n",
      "Epoch[20/80], Step [250/600], Reconst Loss: 228.3077, KL Div: 15.5939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[20/80], Step [300/600], Reconst Loss: 216.4073, KL Div: 15.5108\n",
      "Epoch[20/80], Step [350/600], Reconst Loss: 217.7237, KL Div: 15.3318\n",
      "Epoch[20/80], Step [400/600], Reconst Loss: 231.0179, KL Div: 15.0729\n",
      "Epoch[20/80], Step [450/600], Reconst Loss: 227.7372, KL Div: 14.9825\n",
      "Epoch[20/80], Step [500/600], Reconst Loss: 227.7420, KL Div: 14.6122\n",
      "Epoch[20/80], Step [550/600], Reconst Loss: 222.6200, KL Div: 15.2958\n",
      "Epoch[20/80], Step [600/600], Reconst Loss: 225.2999, KL Div: 16.1211\n",
      "Epoch[21/80], Step [50/600], Reconst Loss: 217.2043, KL Div: 14.8722\n",
      "Epoch[21/80], Step [100/600], Reconst Loss: 222.6296, KL Div: 16.3898\n",
      "Epoch[21/80], Step [150/600], Reconst Loss: 226.7141, KL Div: 15.6371\n",
      "Epoch[21/80], Step [200/600], Reconst Loss: 215.6023, KL Div: 15.0672\n",
      "Epoch[21/80], Step [250/600], Reconst Loss: 217.1675, KL Div: 15.4614\n",
      "Epoch[21/80], Step [300/600], Reconst Loss: 228.6756, KL Div: 14.5369\n",
      "Epoch[21/80], Step [350/600], Reconst Loss: 228.3686, KL Div: 15.8855\n",
      "Epoch[21/80], Step [400/600], Reconst Loss: 227.0084, KL Div: 15.0674\n",
      "Epoch[21/80], Step [450/600], Reconst Loss: 215.5118, KL Div: 15.5413\n",
      "Epoch[21/80], Step [500/600], Reconst Loss: 223.1212, KL Div: 15.1146\n",
      "Epoch[21/80], Step [550/600], Reconst Loss: 239.1723, KL Div: 14.5803\n",
      "Epoch[21/80], Step [600/600], Reconst Loss: 230.0997, KL Div: 15.6456\n",
      "Epoch[22/80], Step [50/600], Reconst Loss: 226.6896, KL Div: 15.2392\n",
      "Epoch[22/80], Step [100/600], Reconst Loss: 222.6427, KL Div: 15.3946\n",
      "Epoch[22/80], Step [150/600], Reconst Loss: 224.4592, KL Div: 15.2311\n",
      "Epoch[22/80], Step [200/600], Reconst Loss: 226.1125, KL Div: 15.8939\n",
      "Epoch[22/80], Step [250/600], Reconst Loss: 233.1856, KL Div: 16.3287\n",
      "Epoch[22/80], Step [300/600], Reconst Loss: 227.8854, KL Div: 15.3299\n",
      "Epoch[22/80], Step [350/600], Reconst Loss: 218.3380, KL Div: 15.5183\n",
      "Epoch[22/80], Step [400/600], Reconst Loss: 228.9957, KL Div: 15.6442\n",
      "Epoch[22/80], Step [450/600], Reconst Loss: 214.2295, KL Div: 15.6423\n",
      "Epoch[22/80], Step [500/600], Reconst Loss: 237.2724, KL Div: 16.9168\n",
      "Epoch[22/80], Step [550/600], Reconst Loss: 218.1756, KL Div: 15.5893\n",
      "Epoch[22/80], Step [600/600], Reconst Loss: 213.0624, KL Div: 15.4214\n",
      "Epoch[23/80], Step [50/600], Reconst Loss: 222.7312, KL Div: 15.3262\n",
      "Epoch[23/80], Step [100/600], Reconst Loss: 228.2595, KL Div: 15.3389\n",
      "Epoch[23/80], Step [150/600], Reconst Loss: 222.2022, KL Div: 16.1734\n",
      "Epoch[23/80], Step [200/600], Reconst Loss: 247.7041, KL Div: 15.0784\n",
      "Epoch[23/80], Step [250/600], Reconst Loss: 224.1987, KL Div: 15.5274\n",
      "Epoch[23/80], Step [300/600], Reconst Loss: 233.5113, KL Div: 14.9561\n",
      "Epoch[23/80], Step [350/600], Reconst Loss: 224.1297, KL Div: 14.7555\n",
      "Epoch[23/80], Step [400/600], Reconst Loss: 227.6353, KL Div: 15.5144\n",
      "Epoch[23/80], Step [450/600], Reconst Loss: 215.3033, KL Div: 15.7329\n",
      "Epoch[23/80], Step [500/600], Reconst Loss: 212.3004, KL Div: 16.3967\n",
      "Epoch[23/80], Step [550/600], Reconst Loss: 228.4329, KL Div: 15.3573\n",
      "Epoch[23/80], Step [600/600], Reconst Loss: 230.3214, KL Div: 15.2566\n",
      "Epoch[24/80], Step [50/600], Reconst Loss: 214.2482, KL Div: 16.0704\n",
      "Epoch[24/80], Step [100/600], Reconst Loss: 226.8364, KL Div: 15.7919\n",
      "Epoch[24/80], Step [150/600], Reconst Loss: 223.7947, KL Div: 15.6017\n",
      "Epoch[24/80], Step [200/600], Reconst Loss: 222.8466, KL Div: 15.7838\n",
      "Epoch[24/80], Step [250/600], Reconst Loss: 230.0578, KL Div: 15.3247\n",
      "Epoch[24/80], Step [300/600], Reconst Loss: 230.5619, KL Div: 15.4468\n",
      "Epoch[24/80], Step [350/600], Reconst Loss: 230.0693, KL Div: 14.5772\n",
      "Epoch[24/80], Step [400/600], Reconst Loss: 215.4117, KL Div: 15.2049\n",
      "Epoch[24/80], Step [450/600], Reconst Loss: 225.3636, KL Div: 15.7943\n",
      "Epoch[24/80], Step [500/600], Reconst Loss: 231.7118, KL Div: 14.6077\n",
      "Epoch[24/80], Step [550/600], Reconst Loss: 220.3759, KL Div: 15.0305\n",
      "Epoch[24/80], Step [600/600], Reconst Loss: 225.1046, KL Div: 14.9781\n",
      "Epoch[25/80], Step [50/600], Reconst Loss: 219.9612, KL Div: 15.0296\n",
      "Epoch[25/80], Step [100/600], Reconst Loss: 222.3628, KL Div: 15.7573\n",
      "Epoch[25/80], Step [150/600], Reconst Loss: 224.9076, KL Div: 14.8398\n",
      "Epoch[25/80], Step [200/600], Reconst Loss: 233.1023, KL Div: 15.8425\n",
      "Epoch[25/80], Step [250/600], Reconst Loss: 241.3170, KL Div: 15.4549\n",
      "Epoch[25/80], Step [300/600], Reconst Loss: 232.6621, KL Div: 15.3988\n",
      "Epoch[25/80], Step [350/600], Reconst Loss: 230.0133, KL Div: 14.7039\n",
      "Epoch[25/80], Step [400/600], Reconst Loss: 212.0971, KL Div: 15.7855\n",
      "Epoch[25/80], Step [450/600], Reconst Loss: 230.1119, KL Div: 14.7600\n",
      "Epoch[25/80], Step [500/600], Reconst Loss: 223.6387, KL Div: 15.8403\n",
      "Epoch[25/80], Step [550/600], Reconst Loss: 224.6428, KL Div: 15.2791\n",
      "Epoch[25/80], Step [600/600], Reconst Loss: 229.5639, KL Div: 15.8243\n",
      "Epoch[26/80], Step [50/600], Reconst Loss: 223.2966, KL Div: 15.3446\n",
      "Epoch[26/80], Step [100/600], Reconst Loss: 228.3155, KL Div: 15.2287\n",
      "Epoch[26/80], Step [150/600], Reconst Loss: 229.0135, KL Div: 15.4780\n",
      "Epoch[26/80], Step [200/600], Reconst Loss: 254.1087, KL Div: 14.8573\n",
      "Epoch[26/80], Step [250/600], Reconst Loss: 228.3775, KL Div: 15.1264\n",
      "Epoch[26/80], Step [300/600], Reconst Loss: 240.0996, KL Div: 16.1566\n",
      "Epoch[26/80], Step [350/600], Reconst Loss: 229.5606, KL Div: 15.0575\n",
      "Epoch[26/80], Step [400/600], Reconst Loss: 220.9020, KL Div: 15.7385\n",
      "Epoch[26/80], Step [450/600], Reconst Loss: 218.4988, KL Div: 15.3527\n",
      "Epoch[26/80], Step [500/600], Reconst Loss: 222.8298, KL Div: 15.3722\n",
      "Epoch[26/80], Step [550/600], Reconst Loss: 223.9782, KL Div: 15.5768\n",
      "Epoch[26/80], Step [600/600], Reconst Loss: 239.9221, KL Div: 15.4150\n",
      "Epoch[27/80], Step [50/600], Reconst Loss: 242.4576, KL Div: 15.8346\n",
      "Epoch[27/80], Step [100/600], Reconst Loss: 228.2921, KL Div: 15.5886\n",
      "Epoch[27/80], Step [150/600], Reconst Loss: 231.0590, KL Div: 16.1009\n",
      "Epoch[27/80], Step [200/600], Reconst Loss: 230.9599, KL Div: 15.3620\n",
      "Epoch[27/80], Step [250/600], Reconst Loss: 220.0801, KL Div: 15.2318\n",
      "Epoch[27/80], Step [300/600], Reconst Loss: 218.5545, KL Div: 15.1285\n",
      "Epoch[27/80], Step [350/600], Reconst Loss: 233.4245, KL Div: 16.3925\n",
      "Epoch[27/80], Step [400/600], Reconst Loss: 221.1735, KL Div: 14.8146\n",
      "Epoch[27/80], Step [450/600], Reconst Loss: 210.9318, KL Div: 15.4705\n",
      "Epoch[27/80], Step [500/600], Reconst Loss: 217.2708, KL Div: 14.5131\n",
      "Epoch[27/80], Step [550/600], Reconst Loss: 216.7421, KL Div: 15.5530\n",
      "Epoch[27/80], Step [600/600], Reconst Loss: 225.7090, KL Div: 15.2941\n",
      "Epoch[28/80], Step [50/600], Reconst Loss: 222.8211, KL Div: 14.9379\n",
      "Epoch[28/80], Step [100/600], Reconst Loss: 230.0725, KL Div: 16.0487\n",
      "Epoch[28/80], Step [150/600], Reconst Loss: 234.8710, KL Div: 16.3336\n",
      "Epoch[28/80], Step [200/600], Reconst Loss: 233.8139, KL Div: 14.9482\n",
      "Epoch[28/80], Step [250/600], Reconst Loss: 229.0964, KL Div: 16.0430\n",
      "Epoch[28/80], Step [300/600], Reconst Loss: 224.2229, KL Div: 15.0252\n",
      "Epoch[28/80], Step [350/600], Reconst Loss: 224.7271, KL Div: 15.2398\n",
      "Epoch[28/80], Step [400/600], Reconst Loss: 234.6333, KL Div: 15.2194\n",
      "Epoch[28/80], Step [450/600], Reconst Loss: 221.1101, KL Div: 15.5558\n",
      "Epoch[28/80], Step [500/600], Reconst Loss: 216.4052, KL Div: 14.7846\n",
      "Epoch[28/80], Step [550/600], Reconst Loss: 214.5180, KL Div: 15.7762\n",
      "Epoch[28/80], Step [600/600], Reconst Loss: 220.0379, KL Div: 15.5108\n",
      "Epoch[29/80], Step [50/600], Reconst Loss: 224.6210, KL Div: 15.2590\n",
      "Epoch[29/80], Step [100/600], Reconst Loss: 213.7713, KL Div: 15.4511\n",
      "Epoch[29/80], Step [150/600], Reconst Loss: 227.7535, KL Div: 15.7371\n",
      "Epoch[29/80], Step [200/600], Reconst Loss: 226.9664, KL Div: 14.9462\n",
      "Epoch[29/80], Step [250/600], Reconst Loss: 225.4964, KL Div: 15.0171\n",
      "Epoch[29/80], Step [300/600], Reconst Loss: 228.5197, KL Div: 14.6994\n",
      "Epoch[29/80], Step [350/600], Reconst Loss: 220.1709, KL Div: 15.7982\n",
      "Epoch[29/80], Step [400/600], Reconst Loss: 231.1489, KL Div: 15.6274\n",
      "Epoch[29/80], Step [450/600], Reconst Loss: 229.7076, KL Div: 15.7472\n",
      "Epoch[29/80], Step [500/600], Reconst Loss: 216.3840, KL Div: 15.2766\n",
      "Epoch[29/80], Step [550/600], Reconst Loss: 229.7932, KL Div: 14.8435\n",
      "Epoch[29/80], Step [600/600], Reconst Loss: 225.3640, KL Div: 15.5370\n",
      "Epoch[30/80], Step [50/600], Reconst Loss: 234.9888, KL Div: 15.5640\n",
      "Epoch[30/80], Step [100/600], Reconst Loss: 220.8007, KL Div: 15.1585\n",
      "Epoch[30/80], Step [150/600], Reconst Loss: 237.8677, KL Div: 15.6822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/80], Step [200/600], Reconst Loss: 234.6287, KL Div: 15.6719\n",
      "Epoch[30/80], Step [250/600], Reconst Loss: 219.4107, KL Div: 15.9970\n",
      "Epoch[30/80], Step [300/600], Reconst Loss: 241.6514, KL Div: 14.5534\n",
      "Epoch[30/80], Step [350/600], Reconst Loss: 219.6726, KL Div: 14.5252\n",
      "Epoch[30/80], Step [400/600], Reconst Loss: 224.4201, KL Div: 14.7432\n",
      "Epoch[30/80], Step [450/600], Reconst Loss: 216.1542, KL Div: 15.3976\n",
      "Epoch[30/80], Step [500/600], Reconst Loss: 224.0206, KL Div: 16.0678\n",
      "Epoch[30/80], Step [550/600], Reconst Loss: 221.3311, KL Div: 15.3928\n",
      "Epoch[30/80], Step [600/600], Reconst Loss: 221.1515, KL Div: 15.1941\n",
      "Epoch[31/80], Step [50/600], Reconst Loss: 225.7796, KL Div: 16.0006\n",
      "Epoch[31/80], Step [100/600], Reconst Loss: 222.7178, KL Div: 15.3856\n",
      "Epoch[31/80], Step [150/600], Reconst Loss: 229.3329, KL Div: 15.1075\n",
      "Epoch[31/80], Step [200/600], Reconst Loss: 228.4930, KL Div: 14.8662\n",
      "Epoch[31/80], Step [250/600], Reconst Loss: 229.1513, KL Div: 15.5694\n",
      "Epoch[31/80], Step [300/600], Reconst Loss: 225.0816, KL Div: 14.8556\n",
      "Epoch[31/80], Step [350/600], Reconst Loss: 226.4586, KL Div: 15.5020\n",
      "Epoch[31/80], Step [400/600], Reconst Loss: 220.5732, KL Div: 14.4628\n",
      "Epoch[31/80], Step [450/600], Reconst Loss: 222.0537, KL Div: 15.5350\n",
      "Epoch[31/80], Step [500/600], Reconst Loss: 222.6837, KL Div: 15.5027\n",
      "Epoch[31/80], Step [550/600], Reconst Loss: 223.4865, KL Div: 14.9799\n",
      "Epoch[31/80], Step [600/600], Reconst Loss: 230.2135, KL Div: 15.7944\n",
      "Epoch[32/80], Step [50/600], Reconst Loss: 226.0398, KL Div: 16.1356\n",
      "Epoch[32/80], Step [100/600], Reconst Loss: 216.7291, KL Div: 15.0071\n",
      "Epoch[32/80], Step [150/600], Reconst Loss: 216.3226, KL Div: 15.3592\n",
      "Epoch[32/80], Step [200/600], Reconst Loss: 226.3966, KL Div: 15.3381\n",
      "Epoch[32/80], Step [250/600], Reconst Loss: 234.4955, KL Div: 14.9934\n",
      "Epoch[32/80], Step [300/600], Reconst Loss: 215.6443, KL Div: 15.7228\n",
      "Epoch[32/80], Step [350/600], Reconst Loss: 222.7180, KL Div: 15.0012\n",
      "Epoch[32/80], Step [400/600], Reconst Loss: 216.0881, KL Div: 16.0222\n",
      "Epoch[32/80], Step [450/600], Reconst Loss: 225.1037, KL Div: 15.6354\n",
      "Epoch[32/80], Step [500/600], Reconst Loss: 233.8649, KL Div: 16.2093\n",
      "Epoch[32/80], Step [550/600], Reconst Loss: 212.1292, KL Div: 15.1476\n",
      "Epoch[32/80], Step [600/600], Reconst Loss: 221.2557, KL Div: 15.4378\n",
      "Epoch[33/80], Step [50/600], Reconst Loss: 232.8293, KL Div: 15.9461\n",
      "Epoch[33/80], Step [100/600], Reconst Loss: 233.4729, KL Div: 14.9522\n",
      "Epoch[33/80], Step [150/600], Reconst Loss: 222.4646, KL Div: 15.6436\n",
      "Epoch[33/80], Step [200/600], Reconst Loss: 218.5910, KL Div: 15.2533\n",
      "Epoch[33/80], Step [250/600], Reconst Loss: 233.1333, KL Div: 14.9179\n",
      "Epoch[33/80], Step [300/600], Reconst Loss: 225.2278, KL Div: 16.4616\n",
      "Epoch[33/80], Step [350/600], Reconst Loss: 230.5455, KL Div: 15.3663\n",
      "Epoch[33/80], Step [400/600], Reconst Loss: 215.8478, KL Div: 15.0425\n",
      "Epoch[33/80], Step [450/600], Reconst Loss: 210.2495, KL Div: 15.0081\n",
      "Epoch[33/80], Step [500/600], Reconst Loss: 225.9088, KL Div: 15.4413\n",
      "Epoch[33/80], Step [550/600], Reconst Loss: 221.0634, KL Div: 15.5175\n",
      "Epoch[33/80], Step [600/600], Reconst Loss: 220.9252, KL Div: 15.4295\n",
      "Epoch[34/80], Step [50/600], Reconst Loss: 227.4161, KL Div: 15.2921\n",
      "Epoch[34/80], Step [100/600], Reconst Loss: 213.7476, KL Div: 15.3728\n",
      "Epoch[34/80], Step [150/600], Reconst Loss: 227.9462, KL Div: 15.1178\n",
      "Epoch[34/80], Step [200/600], Reconst Loss: 235.6875, KL Div: 15.5976\n",
      "Epoch[34/80], Step [250/600], Reconst Loss: 225.7453, KL Div: 15.9353\n",
      "Epoch[34/80], Step [300/600], Reconst Loss: 228.9782, KL Div: 15.4810\n",
      "Epoch[34/80], Step [350/600], Reconst Loss: 233.6007, KL Div: 15.1470\n",
      "Epoch[34/80], Step [400/600], Reconst Loss: 222.3036, KL Div: 15.3277\n",
      "Epoch[34/80], Step [450/600], Reconst Loss: 224.7504, KL Div: 15.8003\n",
      "Epoch[34/80], Step [500/600], Reconst Loss: 235.5161, KL Div: 15.7719\n",
      "Epoch[34/80], Step [550/600], Reconst Loss: 231.6778, KL Div: 15.5142\n",
      "Epoch[34/80], Step [600/600], Reconst Loss: 226.3427, KL Div: 15.7018\n",
      "Epoch[35/80], Step [50/600], Reconst Loss: 233.0139, KL Div: 15.0634\n",
      "Epoch[35/80], Step [100/600], Reconst Loss: 220.8004, KL Div: 14.8548\n",
      "Epoch[35/80], Step [150/600], Reconst Loss: 225.8288, KL Div: 14.4902\n",
      "Epoch[35/80], Step [200/600], Reconst Loss: 231.3755, KL Div: 15.2170\n",
      "Epoch[35/80], Step [250/600], Reconst Loss: 233.5469, KL Div: 15.5911\n",
      "Epoch[35/80], Step [300/600], Reconst Loss: 226.0854, KL Div: 15.6878\n",
      "Epoch[35/80], Step [350/600], Reconst Loss: 228.5516, KL Div: 15.3156\n",
      "Epoch[35/80], Step [400/600], Reconst Loss: 219.3980, KL Div: 15.9112\n",
      "Epoch[35/80], Step [450/600], Reconst Loss: 220.9464, KL Div: 15.3586\n",
      "Epoch[35/80], Step [500/600], Reconst Loss: 230.1448, KL Div: 15.5397\n",
      "Epoch[35/80], Step [550/600], Reconst Loss: 229.9570, KL Div: 15.6038\n",
      "Epoch[35/80], Step [600/600], Reconst Loss: 222.5625, KL Div: 15.3784\n",
      "Epoch[36/80], Step [50/600], Reconst Loss: 228.7759, KL Div: 15.2834\n",
      "Epoch[36/80], Step [100/600], Reconst Loss: 223.5339, KL Div: 15.6663\n",
      "Epoch[36/80], Step [150/600], Reconst Loss: 226.9297, KL Div: 14.7486\n",
      "Epoch[36/80], Step [200/600], Reconst Loss: 216.7199, KL Div: 15.2636\n",
      "Epoch[36/80], Step [250/600], Reconst Loss: 234.2110, KL Div: 14.5260\n",
      "Epoch[36/80], Step [300/600], Reconst Loss: 226.9641, KL Div: 15.8028\n",
      "Epoch[36/80], Step [350/600], Reconst Loss: 226.3900, KL Div: 15.7170\n",
      "Epoch[36/80], Step [400/600], Reconst Loss: 214.2060, KL Div: 15.0612\n",
      "Epoch[36/80], Step [450/600], Reconst Loss: 213.9567, KL Div: 14.9440\n",
      "Epoch[36/80], Step [500/600], Reconst Loss: 223.9127, KL Div: 15.5058\n",
      "Epoch[36/80], Step [550/600], Reconst Loss: 230.5602, KL Div: 15.6079\n",
      "Epoch[36/80], Step [600/600], Reconst Loss: 230.2275, KL Div: 15.0808\n",
      "Epoch[37/80], Step [50/600], Reconst Loss: 239.6661, KL Div: 16.0500\n",
      "Epoch[37/80], Step [100/600], Reconst Loss: 222.9019, KL Div: 15.3412\n",
      "Epoch[37/80], Step [150/600], Reconst Loss: 217.8791, KL Div: 15.6853\n",
      "Epoch[37/80], Step [200/600], Reconst Loss: 232.0172, KL Div: 15.6143\n",
      "Epoch[37/80], Step [250/600], Reconst Loss: 236.6906, KL Div: 15.6247\n",
      "Epoch[37/80], Step [300/600], Reconst Loss: 233.3722, KL Div: 15.6938\n",
      "Epoch[37/80], Step [350/600], Reconst Loss: 239.3573, KL Div: 15.0699\n",
      "Epoch[37/80], Step [400/600], Reconst Loss: 224.6340, KL Div: 14.9595\n",
      "Epoch[37/80], Step [450/600], Reconst Loss: 223.1288, KL Div: 15.3971\n",
      "Epoch[37/80], Step [500/600], Reconst Loss: 228.0555, KL Div: 15.3877\n",
      "Epoch[37/80], Step [550/600], Reconst Loss: 219.6856, KL Div: 14.6612\n",
      "Epoch[37/80], Step [600/600], Reconst Loss: 225.4720, KL Div: 16.2191\n",
      "Epoch[38/80], Step [50/600], Reconst Loss: 216.7655, KL Div: 15.3716\n",
      "Epoch[38/80], Step [100/600], Reconst Loss: 229.4396, KL Div: 15.2837\n",
      "Epoch[38/80], Step [150/600], Reconst Loss: 225.2390, KL Div: 15.2385\n",
      "Epoch[38/80], Step [200/600], Reconst Loss: 235.6984, KL Div: 15.5874\n",
      "Epoch[38/80], Step [250/600], Reconst Loss: 229.5597, KL Div: 15.1299\n",
      "Epoch[38/80], Step [300/600], Reconst Loss: 226.2445, KL Div: 16.1664\n",
      "Epoch[38/80], Step [350/600], Reconst Loss: 215.8453, KL Div: 15.5910\n",
      "Epoch[38/80], Step [400/600], Reconst Loss: 241.1331, KL Div: 15.9155\n",
      "Epoch[38/80], Step [450/600], Reconst Loss: 212.5262, KL Div: 15.1810\n",
      "Epoch[38/80], Step [500/600], Reconst Loss: 220.9356, KL Div: 15.2524\n",
      "Epoch[38/80], Step [550/600], Reconst Loss: 206.1864, KL Div: 14.9723\n",
      "Epoch[38/80], Step [600/600], Reconst Loss: 219.6198, KL Div: 15.6813\n",
      "Epoch[39/80], Step [50/600], Reconst Loss: 230.4427, KL Div: 15.7222\n",
      "Epoch[39/80], Step [100/600], Reconst Loss: 222.0617, KL Div: 16.3163\n",
      "Epoch[39/80], Step [150/600], Reconst Loss: 230.7244, KL Div: 15.2719\n",
      "Epoch[39/80], Step [200/600], Reconst Loss: 234.2234, KL Div: 15.4879\n",
      "Epoch[39/80], Step [250/600], Reconst Loss: 242.2206, KL Div: 16.3865\n",
      "Epoch[39/80], Step [300/600], Reconst Loss: 220.1312, KL Div: 14.7633\n",
      "Epoch[39/80], Step [350/600], Reconst Loss: 232.2602, KL Div: 14.9503\n",
      "Epoch[39/80], Step [400/600], Reconst Loss: 221.0383, KL Div: 15.4557\n",
      "Epoch[39/80], Step [450/600], Reconst Loss: 220.8606, KL Div: 15.9507\n",
      "Epoch[39/80], Step [500/600], Reconst Loss: 224.0990, KL Div: 15.3594\n",
      "Epoch[39/80], Step [550/600], Reconst Loss: 225.4116, KL Div: 15.2040\n",
      "Epoch[39/80], Step [600/600], Reconst Loss: 222.6873, KL Div: 15.5075\n",
      "Epoch[40/80], Step [50/600], Reconst Loss: 220.9134, KL Div: 15.3158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[40/80], Step [100/600], Reconst Loss: 217.2129, KL Div: 15.5538\n",
      "Epoch[40/80], Step [150/600], Reconst Loss: 224.4528, KL Div: 14.8767\n",
      "Epoch[40/80], Step [200/600], Reconst Loss: 241.6776, KL Div: 14.6458\n",
      "Epoch[40/80], Step [250/600], Reconst Loss: 234.5568, KL Div: 15.0631\n",
      "Epoch[40/80], Step [300/600], Reconst Loss: 220.3762, KL Div: 15.0421\n",
      "Epoch[40/80], Step [350/600], Reconst Loss: 218.1153, KL Div: 14.8836\n",
      "Epoch[40/80], Step [400/600], Reconst Loss: 213.8252, KL Div: 15.9797\n",
      "Epoch[40/80], Step [450/600], Reconst Loss: 224.7205, KL Div: 15.4808\n",
      "Epoch[40/80], Step [500/600], Reconst Loss: 228.6207, KL Div: 15.3695\n",
      "Epoch[40/80], Step [550/600], Reconst Loss: 221.4709, KL Div: 15.9363\n",
      "Epoch[40/80], Step [600/600], Reconst Loss: 220.1657, KL Div: 14.7539\n",
      "Epoch[41/80], Step [50/600], Reconst Loss: 237.7005, KL Div: 15.6657\n",
      "Epoch[41/80], Step [100/600], Reconst Loss: 236.8973, KL Div: 15.1609\n",
      "Epoch[41/80], Step [150/600], Reconst Loss: 215.6556, KL Div: 14.8893\n",
      "Epoch[41/80], Step [200/600], Reconst Loss: 223.5110, KL Div: 15.0317\n",
      "Epoch[41/80], Step [250/600], Reconst Loss: 229.6407, KL Div: 15.5923\n",
      "Epoch[41/80], Step [300/600], Reconst Loss: 220.2003, KL Div: 16.2526\n",
      "Epoch[41/80], Step [350/600], Reconst Loss: 230.5602, KL Div: 15.9901\n",
      "Epoch[41/80], Step [400/600], Reconst Loss: 236.4367, KL Div: 15.3195\n",
      "Epoch[41/80], Step [450/600], Reconst Loss: 219.5748, KL Div: 15.5157\n",
      "Epoch[41/80], Step [500/600], Reconst Loss: 225.1281, KL Div: 15.3394\n",
      "Epoch[41/80], Step [550/600], Reconst Loss: 222.4126, KL Div: 15.0895\n",
      "Epoch[41/80], Step [600/600], Reconst Loss: 222.8393, KL Div: 14.8088\n",
      "Epoch[42/80], Step [50/600], Reconst Loss: 222.0045, KL Div: 15.3442\n",
      "Epoch[42/80], Step [100/600], Reconst Loss: 212.3162, KL Div: 15.8546\n",
      "Epoch[42/80], Step [150/600], Reconst Loss: 235.8843, KL Div: 15.8915\n",
      "Epoch[42/80], Step [200/600], Reconst Loss: 234.7882, KL Div: 15.3350\n",
      "Epoch[42/80], Step [250/600], Reconst Loss: 216.3813, KL Div: 15.1533\n",
      "Epoch[42/80], Step [300/600], Reconst Loss: 217.7886, KL Div: 15.1009\n",
      "Epoch[42/80], Step [350/600], Reconst Loss: 224.8668, KL Div: 15.2830\n",
      "Epoch[42/80], Step [400/600], Reconst Loss: 223.0385, KL Div: 15.2761\n",
      "Epoch[42/80], Step [450/600], Reconst Loss: 220.2631, KL Div: 15.5182\n",
      "Epoch[42/80], Step [500/600], Reconst Loss: 235.7554, KL Div: 15.4997\n",
      "Epoch[42/80], Step [550/600], Reconst Loss: 230.2326, KL Div: 15.5124\n",
      "Epoch[42/80], Step [600/600], Reconst Loss: 225.8477, KL Div: 16.1346\n",
      "Epoch[43/80], Step [50/600], Reconst Loss: 233.1538, KL Div: 15.9045\n",
      "Epoch[43/80], Step [100/600], Reconst Loss: 216.5278, KL Div: 15.2523\n",
      "Epoch[43/80], Step [150/600], Reconst Loss: 230.5600, KL Div: 14.6961\n",
      "Epoch[43/80], Step [200/600], Reconst Loss: 233.7308, KL Div: 15.7473\n",
      "Epoch[43/80], Step [250/600], Reconst Loss: 235.1617, KL Div: 14.7095\n",
      "Epoch[43/80], Step [300/600], Reconst Loss: 219.1131, KL Div: 15.1592\n",
      "Epoch[43/80], Step [350/600], Reconst Loss: 227.5184, KL Div: 15.2246\n",
      "Epoch[43/80], Step [400/600], Reconst Loss: 235.5350, KL Div: 15.0396\n",
      "Epoch[43/80], Step [450/600], Reconst Loss: 207.2412, KL Div: 15.5082\n",
      "Epoch[43/80], Step [500/600], Reconst Loss: 233.2222, KL Div: 15.5503\n",
      "Epoch[43/80], Step [550/600], Reconst Loss: 221.6146, KL Div: 14.7192\n",
      "Epoch[43/80], Step [600/600], Reconst Loss: 239.8698, KL Div: 15.7967\n",
      "Epoch[44/80], Step [50/600], Reconst Loss: 224.3683, KL Div: 15.9507\n",
      "Epoch[44/80], Step [100/600], Reconst Loss: 216.2051, KL Div: 15.4634\n",
      "Epoch[44/80], Step [150/600], Reconst Loss: 223.1464, KL Div: 15.5731\n",
      "Epoch[44/80], Step [200/600], Reconst Loss: 230.4806, KL Div: 14.9770\n",
      "Epoch[44/80], Step [250/600], Reconst Loss: 222.5476, KL Div: 15.4839\n",
      "Epoch[44/80], Step [300/600], Reconst Loss: 221.3269, KL Div: 15.5454\n",
      "Epoch[44/80], Step [350/600], Reconst Loss: 210.3379, KL Div: 15.6996\n",
      "Epoch[44/80], Step [400/600], Reconst Loss: 238.1335, KL Div: 15.6681\n",
      "Epoch[44/80], Step [450/600], Reconst Loss: 222.6807, KL Div: 15.2307\n",
      "Epoch[44/80], Step [500/600], Reconst Loss: 214.4834, KL Div: 15.3469\n",
      "Epoch[44/80], Step [550/600], Reconst Loss: 212.4250, KL Div: 15.4690\n",
      "Epoch[44/80], Step [600/600], Reconst Loss: 219.8660, KL Div: 16.2672\n",
      "Epoch[45/80], Step [50/600], Reconst Loss: 218.1875, KL Div: 15.3981\n",
      "Epoch[45/80], Step [100/600], Reconst Loss: 226.0949, KL Div: 15.8454\n",
      "Epoch[45/80], Step [150/600], Reconst Loss: 228.3653, KL Div: 16.3187\n",
      "Epoch[45/80], Step [200/600], Reconst Loss: 230.3179, KL Div: 15.4869\n",
      "Epoch[45/80], Step [250/600], Reconst Loss: 231.6557, KL Div: 14.9587\n",
      "Epoch[45/80], Step [300/600], Reconst Loss: 227.0640, KL Div: 15.8639\n",
      "Epoch[45/80], Step [350/600], Reconst Loss: 235.9884, KL Div: 15.8074\n",
      "Epoch[45/80], Step [400/600], Reconst Loss: 230.8062, KL Div: 16.0141\n",
      "Epoch[45/80], Step [450/600], Reconst Loss: 223.9076, KL Div: 15.4675\n",
      "Epoch[45/80], Step [500/600], Reconst Loss: 215.0896, KL Div: 15.3823\n",
      "Epoch[45/80], Step [550/600], Reconst Loss: 238.6103, KL Div: 15.7753\n",
      "Epoch[45/80], Step [600/600], Reconst Loss: 225.8911, KL Div: 15.5985\n",
      "Epoch[46/80], Step [50/600], Reconst Loss: 223.6374, KL Div: 15.3340\n",
      "Epoch[46/80], Step [100/600], Reconst Loss: 221.5377, KL Div: 15.0012\n",
      "Epoch[46/80], Step [150/600], Reconst Loss: 222.1174, KL Div: 15.3178\n",
      "Epoch[46/80], Step [200/600], Reconst Loss: 228.2241, KL Div: 15.5804\n",
      "Epoch[46/80], Step [250/600], Reconst Loss: 227.8689, KL Div: 14.2962\n",
      "Epoch[46/80], Step [300/600], Reconst Loss: 220.0674, KL Div: 15.6725\n",
      "Epoch[46/80], Step [350/600], Reconst Loss: 234.1010, KL Div: 14.8952\n",
      "Epoch[46/80], Step [400/600], Reconst Loss: 226.1404, KL Div: 14.8180\n",
      "Epoch[46/80], Step [450/600], Reconst Loss: 207.7737, KL Div: 15.0730\n",
      "Epoch[46/80], Step [500/600], Reconst Loss: 217.5262, KL Div: 15.3310\n",
      "Epoch[46/80], Step [550/600], Reconst Loss: 226.3267, KL Div: 15.5641\n",
      "Epoch[46/80], Step [600/600], Reconst Loss: 221.9619, KL Div: 15.6053\n",
      "Epoch[47/80], Step [50/600], Reconst Loss: 227.7373, KL Div: 15.7416\n",
      "Epoch[47/80], Step [100/600], Reconst Loss: 221.3595, KL Div: 14.7100\n",
      "Epoch[47/80], Step [150/600], Reconst Loss: 224.7407, KL Div: 15.5616\n",
      "Epoch[47/80], Step [200/600], Reconst Loss: 213.9797, KL Div: 15.0964\n",
      "Epoch[47/80], Step [250/600], Reconst Loss: 215.2277, KL Div: 15.6982\n",
      "Epoch[47/80], Step [300/600], Reconst Loss: 228.0594, KL Div: 15.4215\n",
      "Epoch[47/80], Step [350/600], Reconst Loss: 238.6904, KL Div: 14.8715\n",
      "Epoch[47/80], Step [400/600], Reconst Loss: 216.5090, KL Div: 16.2372\n",
      "Epoch[47/80], Step [450/600], Reconst Loss: 229.9631, KL Div: 15.8367\n",
      "Epoch[47/80], Step [500/600], Reconst Loss: 215.3769, KL Div: 15.6351\n",
      "Epoch[47/80], Step [550/600], Reconst Loss: 228.4104, KL Div: 15.7450\n",
      "Epoch[47/80], Step [600/600], Reconst Loss: 228.3087, KL Div: 15.1227\n",
      "Epoch[48/80], Step [50/600], Reconst Loss: 221.0415, KL Div: 16.1419\n",
      "Epoch[48/80], Step [100/600], Reconst Loss: 217.5919, KL Div: 14.3568\n",
      "Epoch[48/80], Step [150/600], Reconst Loss: 224.6266, KL Div: 15.5647\n",
      "Epoch[48/80], Step [200/600], Reconst Loss: 220.5036, KL Div: 15.8638\n",
      "Epoch[48/80], Step [250/600], Reconst Loss: 227.1869, KL Div: 15.0319\n",
      "Epoch[48/80], Step [300/600], Reconst Loss: 225.6875, KL Div: 15.4041\n",
      "Epoch[48/80], Step [350/600], Reconst Loss: 224.2057, KL Div: 15.8926\n",
      "Epoch[48/80], Step [400/600], Reconst Loss: 215.2956, KL Div: 15.1192\n",
      "Epoch[48/80], Step [450/600], Reconst Loss: 208.8507, KL Div: 15.3962\n",
      "Epoch[48/80], Step [500/600], Reconst Loss: 235.9890, KL Div: 14.8754\n",
      "Epoch[48/80], Step [550/600], Reconst Loss: 228.2304, KL Div: 15.2706\n",
      "Epoch[48/80], Step [600/600], Reconst Loss: 216.0368, KL Div: 14.9406\n",
      "Epoch[49/80], Step [50/600], Reconst Loss: 226.2188, KL Div: 15.2790\n",
      "Epoch[49/80], Step [100/600], Reconst Loss: 218.2312, KL Div: 15.2891\n",
      "Epoch[49/80], Step [150/600], Reconst Loss: 232.0574, KL Div: 14.9600\n",
      "Epoch[49/80], Step [200/600], Reconst Loss: 223.8809, KL Div: 15.4840\n",
      "Epoch[49/80], Step [250/600], Reconst Loss: 220.8476, KL Div: 14.7990\n",
      "Epoch[49/80], Step [300/600], Reconst Loss: 245.5613, KL Div: 15.6422\n",
      "Epoch[49/80], Step [350/600], Reconst Loss: 224.9595, KL Div: 14.9714\n",
      "Epoch[49/80], Step [400/600], Reconst Loss: 220.8225, KL Div: 15.1414\n",
      "Epoch[49/80], Step [450/600], Reconst Loss: 217.8201, KL Div: 14.8382\n",
      "Epoch[49/80], Step [500/600], Reconst Loss: 230.0437, KL Div: 15.2101\n",
      "Epoch[49/80], Step [550/600], Reconst Loss: 221.0319, KL Div: 16.1430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49/80], Step [600/600], Reconst Loss: 242.8629, KL Div: 14.8794\n",
      "Epoch[50/80], Step [50/600], Reconst Loss: 220.3703, KL Div: 15.6066\n",
      "Epoch[50/80], Step [100/600], Reconst Loss: 216.9826, KL Div: 14.8425\n",
      "Epoch[50/80], Step [150/600], Reconst Loss: 229.9801, KL Div: 16.0906\n",
      "Epoch[50/80], Step [200/600], Reconst Loss: 208.8636, KL Div: 14.7475\n",
      "Epoch[50/80], Step [250/600], Reconst Loss: 223.2682, KL Div: 15.0819\n",
      "Epoch[50/80], Step [300/600], Reconst Loss: 217.0771, KL Div: 15.0012\n",
      "Epoch[50/80], Step [350/600], Reconst Loss: 220.2097, KL Div: 15.6120\n",
      "Epoch[50/80], Step [400/600], Reconst Loss: 214.5755, KL Div: 14.9468\n",
      "Epoch[50/80], Step [450/600], Reconst Loss: 227.2109, KL Div: 15.9642\n",
      "Epoch[50/80], Step [500/600], Reconst Loss: 219.3345, KL Div: 15.0749\n",
      "Epoch[50/80], Step [550/600], Reconst Loss: 225.4042, KL Div: 15.0492\n",
      "Epoch[50/80], Step [600/600], Reconst Loss: 230.2405, KL Div: 15.5447\n",
      "Epoch[51/80], Step [50/600], Reconst Loss: 226.4652, KL Div: 14.8958\n",
      "Epoch[51/80], Step [100/600], Reconst Loss: 222.4957, KL Div: 15.4155\n",
      "Epoch[51/80], Step [150/600], Reconst Loss: 225.6036, KL Div: 15.4010\n",
      "Epoch[51/80], Step [200/600], Reconst Loss: 227.5965, KL Div: 16.0819\n",
      "Epoch[51/80], Step [250/600], Reconst Loss: 229.3165, KL Div: 15.4069\n",
      "Epoch[51/80], Step [300/600], Reconst Loss: 224.3710, KL Div: 15.0830\n",
      "Epoch[51/80], Step [350/600], Reconst Loss: 229.4992, KL Div: 15.1853\n",
      "Epoch[51/80], Step [400/600], Reconst Loss: 217.7184, KL Div: 15.2677\n",
      "Epoch[51/80], Step [450/600], Reconst Loss: 220.2394, KL Div: 14.8097\n",
      "Epoch[51/80], Step [500/600], Reconst Loss: 228.6477, KL Div: 15.5954\n",
      "Epoch[51/80], Step [550/600], Reconst Loss: 225.6914, KL Div: 15.1956\n",
      "Epoch[51/80], Step [600/600], Reconst Loss: 224.9410, KL Div: 14.8670\n",
      "Epoch[52/80], Step [50/600], Reconst Loss: 226.5852, KL Div: 15.1571\n",
      "Epoch[52/80], Step [100/600], Reconst Loss: 222.1704, KL Div: 15.9091\n",
      "Epoch[52/80], Step [150/600], Reconst Loss: 227.6744, KL Div: 14.9760\n",
      "Epoch[52/80], Step [200/600], Reconst Loss: 229.4590, KL Div: 16.2543\n",
      "Epoch[52/80], Step [250/600], Reconst Loss: 221.4022, KL Div: 14.6940\n",
      "Epoch[52/80], Step [300/600], Reconst Loss: 223.3465, KL Div: 15.4608\n",
      "Epoch[52/80], Step [350/600], Reconst Loss: 231.0641, KL Div: 15.6517\n",
      "Epoch[52/80], Step [400/600], Reconst Loss: 230.6387, KL Div: 14.9418\n",
      "Epoch[52/80], Step [450/600], Reconst Loss: 217.6212, KL Div: 15.4583\n",
      "Epoch[52/80], Step [500/600], Reconst Loss: 218.0319, KL Div: 15.4467\n",
      "Epoch[52/80], Step [550/600], Reconst Loss: 227.2648, KL Div: 15.6755\n",
      "Epoch[52/80], Step [600/600], Reconst Loss: 225.8135, KL Div: 15.3807\n",
      "Epoch[53/80], Step [50/600], Reconst Loss: 218.0071, KL Div: 15.4115\n",
      "Epoch[53/80], Step [100/600], Reconst Loss: 221.1974, KL Div: 14.8927\n",
      "Epoch[53/80], Step [150/600], Reconst Loss: 228.9769, KL Div: 15.8340\n",
      "Epoch[53/80], Step [200/600], Reconst Loss: 243.2274, KL Div: 14.9424\n",
      "Epoch[53/80], Step [250/600], Reconst Loss: 222.7263, KL Div: 15.7901\n",
      "Epoch[53/80], Step [300/600], Reconst Loss: 218.2043, KL Div: 15.0609\n",
      "Epoch[53/80], Step [350/600], Reconst Loss: 221.7692, KL Div: 15.5604\n",
      "Epoch[53/80], Step [400/600], Reconst Loss: 226.2476, KL Div: 15.1285\n",
      "Epoch[53/80], Step [450/600], Reconst Loss: 218.6215, KL Div: 15.7632\n",
      "Epoch[53/80], Step [500/600], Reconst Loss: 228.2858, KL Div: 15.0712\n",
      "Epoch[53/80], Step [550/600], Reconst Loss: 224.9059, KL Div: 15.3515\n",
      "Epoch[53/80], Step [600/600], Reconst Loss: 221.6897, KL Div: 15.2458\n",
      "Epoch[54/80], Step [50/600], Reconst Loss: 238.9216, KL Div: 16.0595\n",
      "Epoch[54/80], Step [100/600], Reconst Loss: 233.0276, KL Div: 15.8084\n",
      "Epoch[54/80], Step [150/600], Reconst Loss: 211.8018, KL Div: 16.0529\n",
      "Epoch[54/80], Step [200/600], Reconst Loss: 238.0439, KL Div: 14.6456\n",
      "Epoch[54/80], Step [250/600], Reconst Loss: 213.6171, KL Div: 15.9243\n",
      "Epoch[54/80], Step [300/600], Reconst Loss: 223.8108, KL Div: 15.2616\n",
      "Epoch[54/80], Step [350/600], Reconst Loss: 228.1569, KL Div: 15.0542\n",
      "Epoch[54/80], Step [400/600], Reconst Loss: 215.8203, KL Div: 14.9460\n",
      "Epoch[54/80], Step [450/600], Reconst Loss: 222.7752, KL Div: 15.0221\n",
      "Epoch[54/80], Step [500/600], Reconst Loss: 223.2146, KL Div: 15.2187\n",
      "Epoch[54/80], Step [550/600], Reconst Loss: 224.5321, KL Div: 15.4918\n",
      "Epoch[54/80], Step [600/600], Reconst Loss: 220.9031, KL Div: 16.2794\n",
      "Epoch[55/80], Step [50/600], Reconst Loss: 223.6069, KL Div: 14.7356\n",
      "Epoch[55/80], Step [100/600], Reconst Loss: 210.5916, KL Div: 15.1511\n",
      "Epoch[55/80], Step [150/600], Reconst Loss: 218.0440, KL Div: 14.7939\n",
      "Epoch[55/80], Step [200/600], Reconst Loss: 215.9039, KL Div: 15.2714\n",
      "Epoch[55/80], Step [250/600], Reconst Loss: 224.3347, KL Div: 15.3276\n",
      "Epoch[55/80], Step [300/600], Reconst Loss: 214.5856, KL Div: 16.1936\n",
      "Epoch[55/80], Step [350/600], Reconst Loss: 233.6792, KL Div: 15.1523\n",
      "Epoch[55/80], Step [400/600], Reconst Loss: 230.6102, KL Div: 15.1736\n",
      "Epoch[55/80], Step [450/600], Reconst Loss: 228.7775, KL Div: 14.8190\n",
      "Epoch[55/80], Step [500/600], Reconst Loss: 220.6908, KL Div: 15.6277\n",
      "Epoch[55/80], Step [550/600], Reconst Loss: 227.7433, KL Div: 15.0053\n",
      "Epoch[55/80], Step [600/600], Reconst Loss: 221.4404, KL Div: 15.5489\n",
      "Epoch[56/80], Step [50/600], Reconst Loss: 222.7930, KL Div: 15.2729\n",
      "Epoch[56/80], Step [100/600], Reconst Loss: 220.2383, KL Div: 15.2756\n",
      "Epoch[56/80], Step [150/600], Reconst Loss: 222.0290, KL Div: 15.0741\n",
      "Epoch[56/80], Step [200/600], Reconst Loss: 227.4059, KL Div: 15.2490\n",
      "Epoch[56/80], Step [250/600], Reconst Loss: 223.9710, KL Div: 15.0595\n",
      "Epoch[56/80], Step [300/600], Reconst Loss: 238.1287, KL Div: 15.6434\n",
      "Epoch[56/80], Step [350/600], Reconst Loss: 226.1708, KL Div: 14.8925\n",
      "Epoch[56/80], Step [400/600], Reconst Loss: 241.4652, KL Div: 15.4072\n",
      "Epoch[56/80], Step [450/600], Reconst Loss: 222.8654, KL Div: 15.5693\n",
      "Epoch[56/80], Step [500/600], Reconst Loss: 223.9363, KL Div: 15.9425\n",
      "Epoch[56/80], Step [550/600], Reconst Loss: 219.6065, KL Div: 14.8508\n",
      "Epoch[56/80], Step [600/600], Reconst Loss: 210.0643, KL Div: 15.8735\n",
      "Epoch[57/80], Step [50/600], Reconst Loss: 223.9864, KL Div: 15.7451\n",
      "Epoch[57/80], Step [100/600], Reconst Loss: 218.8624, KL Div: 15.2537\n",
      "Epoch[57/80], Step [150/600], Reconst Loss: 214.1547, KL Div: 15.6184\n",
      "Epoch[57/80], Step [200/600], Reconst Loss: 236.5731, KL Div: 15.5251\n",
      "Epoch[57/80], Step [250/600], Reconst Loss: 220.9035, KL Div: 15.8531\n",
      "Epoch[57/80], Step [300/600], Reconst Loss: 217.1327, KL Div: 16.1729\n",
      "Epoch[57/80], Step [350/600], Reconst Loss: 208.0537, KL Div: 14.5058\n",
      "Epoch[57/80], Step [400/600], Reconst Loss: 212.8709, KL Div: 15.6443\n",
      "Epoch[57/80], Step [450/600], Reconst Loss: 220.0446, KL Div: 14.8926\n",
      "Epoch[57/80], Step [500/600], Reconst Loss: 227.8611, KL Div: 16.0227\n",
      "Epoch[57/80], Step [550/600], Reconst Loss: 228.5407, KL Div: 14.7377\n",
      "Epoch[57/80], Step [600/600], Reconst Loss: 228.1718, KL Div: 15.2929\n",
      "Epoch[58/80], Step [50/600], Reconst Loss: 222.1693, KL Div: 15.7421\n",
      "Epoch[58/80], Step [100/600], Reconst Loss: 226.1779, KL Div: 15.3789\n",
      "Epoch[58/80], Step [150/600], Reconst Loss: 229.0187, KL Div: 14.9312\n",
      "Epoch[58/80], Step [200/600], Reconst Loss: 226.0377, KL Div: 15.4684\n",
      "Epoch[58/80], Step [250/600], Reconst Loss: 222.7306, KL Div: 15.4410\n",
      "Epoch[58/80], Step [300/600], Reconst Loss: 220.9429, KL Div: 15.7580\n",
      "Epoch[58/80], Step [350/600], Reconst Loss: 225.0910, KL Div: 14.5792\n",
      "Epoch[58/80], Step [400/600], Reconst Loss: 221.1602, KL Div: 15.9607\n",
      "Epoch[58/80], Step [450/600], Reconst Loss: 231.5020, KL Div: 15.7988\n",
      "Epoch[58/80], Step [500/600], Reconst Loss: 228.2174, KL Div: 15.3612\n",
      "Epoch[58/80], Step [550/600], Reconst Loss: 221.0164, KL Div: 15.6824\n",
      "Epoch[58/80], Step [600/600], Reconst Loss: 211.4763, KL Div: 15.2467\n",
      "Epoch[59/80], Step [50/600], Reconst Loss: 226.9556, KL Div: 14.9732\n",
      "Epoch[59/80], Step [100/600], Reconst Loss: 212.8092, KL Div: 15.0954\n",
      "Epoch[59/80], Step [150/600], Reconst Loss: 236.6479, KL Div: 15.7230\n",
      "Epoch[59/80], Step [200/600], Reconst Loss: 229.6008, KL Div: 15.8794\n",
      "Epoch[59/80], Step [250/600], Reconst Loss: 214.3532, KL Div: 14.9937\n",
      "Epoch[59/80], Step [300/600], Reconst Loss: 223.4300, KL Div: 15.4664\n",
      "Epoch[59/80], Step [350/600], Reconst Loss: 223.9263, KL Div: 15.4329\n",
      "Epoch[59/80], Step [400/600], Reconst Loss: 231.1397, KL Div: 15.5497\n",
      "Epoch[59/80], Step [450/600], Reconst Loss: 234.8236, KL Div: 15.7303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[59/80], Step [500/600], Reconst Loss: 244.7207, KL Div: 15.1725\n",
      "Epoch[59/80], Step [550/600], Reconst Loss: 234.4637, KL Div: 15.3538\n",
      "Epoch[59/80], Step [600/600], Reconst Loss: 222.8686, KL Div: 16.2839\n",
      "Epoch[60/80], Step [50/600], Reconst Loss: 234.4224, KL Div: 15.2024\n",
      "Epoch[60/80], Step [100/600], Reconst Loss: 219.8748, KL Div: 15.6019\n",
      "Epoch[60/80], Step [150/600], Reconst Loss: 226.0905, KL Div: 15.2891\n",
      "Epoch[60/80], Step [200/600], Reconst Loss: 228.8453, KL Div: 15.6129\n",
      "Epoch[60/80], Step [250/600], Reconst Loss: 236.7935, KL Div: 15.3096\n",
      "Epoch[60/80], Step [300/600], Reconst Loss: 229.0162, KL Div: 15.0723\n",
      "Epoch[60/80], Step [350/600], Reconst Loss: 229.0191, KL Div: 15.3547\n",
      "Epoch[60/80], Step [400/600], Reconst Loss: 227.7527, KL Div: 15.4549\n",
      "Epoch[60/80], Step [450/600], Reconst Loss: 222.8627, KL Div: 15.1654\n",
      "Epoch[60/80], Step [500/600], Reconst Loss: 220.0172, KL Div: 15.3194\n",
      "Epoch[60/80], Step [550/600], Reconst Loss: 218.7097, KL Div: 15.0155\n",
      "Epoch[60/80], Step [600/600], Reconst Loss: 220.2859, KL Div: 15.2098\n",
      "Epoch[61/80], Step [50/600], Reconst Loss: 227.0053, KL Div: 14.4666\n",
      "Epoch[61/80], Step [100/600], Reconst Loss: 223.0796, KL Div: 15.4404\n",
      "Epoch[61/80], Step [150/600], Reconst Loss: 221.9700, KL Div: 15.6241\n",
      "Epoch[61/80], Step [200/600], Reconst Loss: 228.7706, KL Div: 14.8260\n",
      "Epoch[61/80], Step [250/600], Reconst Loss: 223.8235, KL Div: 15.2623\n",
      "Epoch[61/80], Step [300/600], Reconst Loss: 229.7335, KL Div: 15.4792\n",
      "Epoch[61/80], Step [350/600], Reconst Loss: 211.6374, KL Div: 15.6164\n",
      "Epoch[61/80], Step [400/600], Reconst Loss: 212.7490, KL Div: 15.7662\n",
      "Epoch[61/80], Step [450/600], Reconst Loss: 226.4514, KL Div: 15.4313\n",
      "Epoch[61/80], Step [500/600], Reconst Loss: 233.8128, KL Div: 15.8157\n",
      "Epoch[61/80], Step [550/600], Reconst Loss: 215.1689, KL Div: 15.3087\n",
      "Epoch[61/80], Step [600/600], Reconst Loss: 218.9907, KL Div: 15.6829\n",
      "Epoch[62/80], Step [50/600], Reconst Loss: 232.0991, KL Div: 15.4947\n",
      "Epoch[62/80], Step [100/600], Reconst Loss: 230.6898, KL Div: 15.3326\n",
      "Epoch[62/80], Step [150/600], Reconst Loss: 234.6862, KL Div: 15.3487\n",
      "Epoch[62/80], Step [200/600], Reconst Loss: 220.5236, KL Div: 14.9863\n",
      "Epoch[62/80], Step [250/600], Reconst Loss: 216.9101, KL Div: 15.0944\n",
      "Epoch[62/80], Step [300/600], Reconst Loss: 219.0127, KL Div: 15.2743\n",
      "Epoch[62/80], Step [350/600], Reconst Loss: 221.8866, KL Div: 15.1414\n",
      "Epoch[62/80], Step [400/600], Reconst Loss: 216.7900, KL Div: 15.3643\n",
      "Epoch[62/80], Step [450/600], Reconst Loss: 213.2141, KL Div: 15.0722\n",
      "Epoch[62/80], Step [500/600], Reconst Loss: 221.5717, KL Div: 15.8813\n",
      "Epoch[62/80], Step [550/600], Reconst Loss: 218.7971, KL Div: 15.9933\n",
      "Epoch[62/80], Step [600/600], Reconst Loss: 217.7960, KL Div: 15.6810\n",
      "Epoch[63/80], Step [50/600], Reconst Loss: 225.6552, KL Div: 15.2538\n",
      "Epoch[63/80], Step [100/600], Reconst Loss: 223.1603, KL Div: 15.6600\n",
      "Epoch[63/80], Step [150/600], Reconst Loss: 233.2440, KL Div: 15.4094\n",
      "Epoch[63/80], Step [200/600], Reconst Loss: 218.2936, KL Div: 15.1010\n",
      "Epoch[63/80], Step [250/600], Reconst Loss: 223.7371, KL Div: 15.4755\n",
      "Epoch[63/80], Step [300/600], Reconst Loss: 230.4621, KL Div: 15.3717\n",
      "Epoch[63/80], Step [350/600], Reconst Loss: 220.1205, KL Div: 14.7604\n",
      "Epoch[63/80], Step [400/600], Reconst Loss: 221.2396, KL Div: 15.7020\n",
      "Epoch[63/80], Step [450/600], Reconst Loss: 230.1416, KL Div: 15.6353\n",
      "Epoch[63/80], Step [500/600], Reconst Loss: 225.9330, KL Div: 15.4903\n",
      "Epoch[63/80], Step [550/600], Reconst Loss: 221.0184, KL Div: 14.6637\n",
      "Epoch[63/80], Step [600/600], Reconst Loss: 213.5240, KL Div: 15.5039\n",
      "Epoch[64/80], Step [50/600], Reconst Loss: 220.3670, KL Div: 15.3283\n",
      "Epoch[64/80], Step [100/600], Reconst Loss: 220.6369, KL Div: 15.6048\n",
      "Epoch[64/80], Step [150/600], Reconst Loss: 232.7477, KL Div: 15.7804\n",
      "Epoch[64/80], Step [200/600], Reconst Loss: 219.6521, KL Div: 14.9758\n",
      "Epoch[64/80], Step [250/600], Reconst Loss: 229.2856, KL Div: 14.8715\n",
      "Epoch[64/80], Step [300/600], Reconst Loss: 223.1468, KL Div: 15.3327\n",
      "Epoch[64/80], Step [350/600], Reconst Loss: 221.5696, KL Div: 15.5620\n",
      "Epoch[64/80], Step [400/600], Reconst Loss: 226.9710, KL Div: 15.4619\n",
      "Epoch[64/80], Step [450/600], Reconst Loss: 221.4435, KL Div: 15.1932\n",
      "Epoch[64/80], Step [500/600], Reconst Loss: 228.2900, KL Div: 15.1754\n",
      "Epoch[64/80], Step [550/600], Reconst Loss: 223.4176, KL Div: 15.6119\n",
      "Epoch[64/80], Step [600/600], Reconst Loss: 213.1401, KL Div: 15.2392\n",
      "Epoch[65/80], Step [50/600], Reconst Loss: 231.4328, KL Div: 15.5050\n",
      "Epoch[65/80], Step [100/600], Reconst Loss: 223.1838, KL Div: 15.5945\n",
      "Epoch[65/80], Step [150/600], Reconst Loss: 235.5271, KL Div: 15.5507\n",
      "Epoch[65/80], Step [200/600], Reconst Loss: 226.7398, KL Div: 15.0653\n",
      "Epoch[65/80], Step [250/600], Reconst Loss: 231.7413, KL Div: 15.8693\n",
      "Epoch[65/80], Step [300/600], Reconst Loss: 228.4218, KL Div: 15.7923\n",
      "Epoch[65/80], Step [350/600], Reconst Loss: 231.1620, KL Div: 15.6443\n",
      "Epoch[65/80], Step [400/600], Reconst Loss: 219.5238, KL Div: 15.2145\n",
      "Epoch[65/80], Step [450/600], Reconst Loss: 219.7486, KL Div: 15.7787\n",
      "Epoch[65/80], Step [500/600], Reconst Loss: 212.3093, KL Div: 15.3672\n",
      "Epoch[65/80], Step [550/600], Reconst Loss: 227.5307, KL Div: 15.2621\n",
      "Epoch[65/80], Step [600/600], Reconst Loss: 217.8715, KL Div: 15.5338\n",
      "Epoch[66/80], Step [50/600], Reconst Loss: 229.9993, KL Div: 15.3471\n",
      "Epoch[66/80], Step [100/600], Reconst Loss: 220.8181, KL Div: 14.9657\n",
      "Epoch[66/80], Step [150/600], Reconst Loss: 222.4810, KL Div: 15.3862\n",
      "Epoch[66/80], Step [200/600], Reconst Loss: 229.0582, KL Div: 15.3468\n",
      "Epoch[66/80], Step [250/600], Reconst Loss: 230.2186, KL Div: 16.1159\n",
      "Epoch[66/80], Step [300/600], Reconst Loss: 214.4265, KL Div: 15.5309\n",
      "Epoch[66/80], Step [350/600], Reconst Loss: 227.5955, KL Div: 15.3523\n",
      "Epoch[66/80], Step [400/600], Reconst Loss: 218.8253, KL Div: 15.2127\n",
      "Epoch[66/80], Step [450/600], Reconst Loss: 215.1223, KL Div: 14.8164\n",
      "Epoch[66/80], Step [500/600], Reconst Loss: 219.9557, KL Div: 15.2710\n",
      "Epoch[66/80], Step [550/600], Reconst Loss: 232.3107, KL Div: 14.8045\n",
      "Epoch[66/80], Step [600/600], Reconst Loss: 213.3393, KL Div: 15.7890\n",
      "Epoch[67/80], Step [50/600], Reconst Loss: 218.5390, KL Div: 15.2447\n",
      "Epoch[67/80], Step [100/600], Reconst Loss: 223.4088, KL Div: 15.6714\n",
      "Epoch[67/80], Step [150/600], Reconst Loss: 213.4789, KL Div: 15.0899\n",
      "Epoch[67/80], Step [200/600], Reconst Loss: 215.1653, KL Div: 15.1080\n",
      "Epoch[67/80], Step [250/600], Reconst Loss: 230.3577, KL Div: 15.7846\n",
      "Epoch[67/80], Step [300/600], Reconst Loss: 227.3670, KL Div: 15.2091\n",
      "Epoch[67/80], Step [350/600], Reconst Loss: 222.4344, KL Div: 15.4342\n",
      "Epoch[67/80], Step [400/600], Reconst Loss: 221.9177, KL Div: 15.3782\n",
      "Epoch[67/80], Step [450/600], Reconst Loss: 219.5375, KL Div: 15.2007\n",
      "Epoch[67/80], Step [500/600], Reconst Loss: 224.3907, KL Div: 15.4804\n",
      "Epoch[67/80], Step [550/600], Reconst Loss: 222.6738, KL Div: 15.2266\n",
      "Epoch[67/80], Step [600/600], Reconst Loss: 202.8345, KL Div: 15.0815\n",
      "Epoch[68/80], Step [50/600], Reconst Loss: 240.5368, KL Div: 15.3624\n",
      "Epoch[68/80], Step [100/600], Reconst Loss: 221.9228, KL Div: 15.8114\n",
      "Epoch[68/80], Step [150/600], Reconst Loss: 222.7998, KL Div: 15.1738\n",
      "Epoch[68/80], Step [200/600], Reconst Loss: 227.1946, KL Div: 15.4945\n",
      "Epoch[68/80], Step [250/600], Reconst Loss: 228.1080, KL Div: 15.2514\n",
      "Epoch[68/80], Step [300/600], Reconst Loss: 229.7049, KL Div: 14.8822\n",
      "Epoch[68/80], Step [350/600], Reconst Loss: 228.5867, KL Div: 15.6637\n",
      "Epoch[68/80], Step [400/600], Reconst Loss: 233.5682, KL Div: 16.0727\n",
      "Epoch[68/80], Step [450/600], Reconst Loss: 214.8244, KL Div: 15.5084\n",
      "Epoch[68/80], Step [500/600], Reconst Loss: 242.7186, KL Div: 15.6185\n",
      "Epoch[68/80], Step [550/600], Reconst Loss: 219.0573, KL Div: 15.1408\n",
      "Epoch[68/80], Step [600/600], Reconst Loss: 214.9814, KL Div: 15.3075\n",
      "Epoch[69/80], Step [50/600], Reconst Loss: 223.4602, KL Div: 15.8817\n",
      "Epoch[69/80], Step [100/600], Reconst Loss: 208.8937, KL Div: 15.2077\n",
      "Epoch[69/80], Step [150/600], Reconst Loss: 221.8169, KL Div: 15.1386\n",
      "Epoch[69/80], Step [200/600], Reconst Loss: 219.9690, KL Div: 15.5890\n",
      "Epoch[69/80], Step [250/600], Reconst Loss: 239.3438, KL Div: 15.2299\n",
      "Epoch[69/80], Step [300/600], Reconst Loss: 218.1122, KL Div: 14.8781\n",
      "Epoch[69/80], Step [350/600], Reconst Loss: 233.8404, KL Div: 15.2956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[69/80], Step [400/600], Reconst Loss: 228.9365, KL Div: 15.3566\n",
      "Epoch[69/80], Step [450/600], Reconst Loss: 207.8805, KL Div: 14.8201\n",
      "Epoch[69/80], Step [500/600], Reconst Loss: 222.4449, KL Div: 15.6873\n",
      "Epoch[69/80], Step [550/600], Reconst Loss: 221.1747, KL Div: 15.1234\n",
      "Epoch[69/80], Step [600/600], Reconst Loss: 218.9840, KL Div: 16.1893\n",
      "Epoch[70/80], Step [50/600], Reconst Loss: 223.7026, KL Div: 16.2849\n",
      "Epoch[70/80], Step [100/600], Reconst Loss: 228.6252, KL Div: 15.3827\n",
      "Epoch[70/80], Step [150/600], Reconst Loss: 234.6234, KL Div: 15.4745\n",
      "Epoch[70/80], Step [200/600], Reconst Loss: 233.8750, KL Div: 15.4892\n",
      "Epoch[70/80], Step [250/600], Reconst Loss: 219.5835, KL Div: 14.4313\n",
      "Epoch[70/80], Step [300/600], Reconst Loss: 215.7886, KL Div: 16.2036\n",
      "Epoch[70/80], Step [350/600], Reconst Loss: 230.1521, KL Div: 15.0495\n",
      "Epoch[70/80], Step [400/600], Reconst Loss: 230.8018, KL Div: 15.5763\n",
      "Epoch[70/80], Step [450/600], Reconst Loss: 222.8168, KL Div: 15.5422\n",
      "Epoch[70/80], Step [500/600], Reconst Loss: 225.5846, KL Div: 15.6218\n",
      "Epoch[70/80], Step [550/600], Reconst Loss: 231.4057, KL Div: 15.2788\n",
      "Epoch[70/80], Step [600/600], Reconst Loss: 224.2408, KL Div: 15.7620\n",
      "Epoch[71/80], Step [50/600], Reconst Loss: 231.6082, KL Div: 15.8147\n",
      "Epoch[71/80], Step [100/600], Reconst Loss: 226.8998, KL Div: 16.0838\n",
      "Epoch[71/80], Step [150/600], Reconst Loss: 225.5913, KL Div: 15.1166\n",
      "Epoch[71/80], Step [200/600], Reconst Loss: 220.1807, KL Div: 15.2200\n",
      "Epoch[71/80], Step [250/600], Reconst Loss: 230.1043, KL Div: 15.4182\n",
      "Epoch[71/80], Step [300/600], Reconst Loss: 219.6444, KL Div: 14.8923\n",
      "Epoch[71/80], Step [350/600], Reconst Loss: 219.7802, KL Div: 15.2490\n",
      "Epoch[71/80], Step [400/600], Reconst Loss: 232.9675, KL Div: 15.3317\n",
      "Epoch[71/80], Step [450/600], Reconst Loss: 224.5534, KL Div: 15.3600\n",
      "Epoch[71/80], Step [500/600], Reconst Loss: 219.6651, KL Div: 14.8518\n",
      "Epoch[71/80], Step [550/600], Reconst Loss: 217.7037, KL Div: 15.5801\n",
      "Epoch[71/80], Step [600/600], Reconst Loss: 216.6037, KL Div: 15.4133\n",
      "Epoch[72/80], Step [50/600], Reconst Loss: 221.7222, KL Div: 15.0938\n",
      "Epoch[72/80], Step [100/600], Reconst Loss: 222.3097, KL Div: 16.0876\n",
      "Epoch[72/80], Step [150/600], Reconst Loss: 230.6620, KL Div: 15.3987\n",
      "Epoch[72/80], Step [200/600], Reconst Loss: 223.9154, KL Div: 14.9267\n",
      "Epoch[72/80], Step [250/600], Reconst Loss: 222.6433, KL Div: 15.2979\n",
      "Epoch[72/80], Step [300/600], Reconst Loss: 222.1419, KL Div: 16.0697\n",
      "Epoch[72/80], Step [350/600], Reconst Loss: 220.3616, KL Div: 15.2246\n",
      "Epoch[72/80], Step [400/600], Reconst Loss: 224.3253, KL Div: 15.8322\n",
      "Epoch[72/80], Step [450/600], Reconst Loss: 215.0264, KL Div: 14.9744\n",
      "Epoch[72/80], Step [500/600], Reconst Loss: 226.3947, KL Div: 15.1834\n",
      "Epoch[72/80], Step [550/600], Reconst Loss: 228.1145, KL Div: 16.5028\n",
      "Epoch[72/80], Step [600/600], Reconst Loss: 217.1651, KL Div: 15.1148\n",
      "Epoch[73/80], Step [50/600], Reconst Loss: 232.0073, KL Div: 16.3622\n",
      "Epoch[73/80], Step [100/600], Reconst Loss: 216.7388, KL Div: 15.2108\n",
      "Epoch[73/80], Step [150/600], Reconst Loss: 225.8025, KL Div: 14.4284\n",
      "Epoch[73/80], Step [200/600], Reconst Loss: 213.3430, KL Div: 15.1749\n",
      "Epoch[73/80], Step [250/600], Reconst Loss: 226.2131, KL Div: 15.4903\n",
      "Epoch[73/80], Step [300/600], Reconst Loss: 229.5172, KL Div: 15.3003\n",
      "Epoch[73/80], Step [350/600], Reconst Loss: 220.9699, KL Div: 15.1682\n",
      "Epoch[73/80], Step [400/600], Reconst Loss: 210.7492, KL Div: 14.7596\n",
      "Epoch[73/80], Step [450/600], Reconst Loss: 225.0020, KL Div: 15.0103\n",
      "Epoch[73/80], Step [500/600], Reconst Loss: 228.8527, KL Div: 14.8982\n",
      "Epoch[73/80], Step [550/600], Reconst Loss: 229.8630, KL Div: 15.0244\n",
      "Epoch[73/80], Step [600/600], Reconst Loss: 232.8995, KL Div: 16.0349\n",
      "Epoch[74/80], Step [50/600], Reconst Loss: 224.7264, KL Div: 14.8712\n",
      "Epoch[74/80], Step [100/600], Reconst Loss: 209.7432, KL Div: 15.8492\n",
      "Epoch[74/80], Step [150/600], Reconst Loss: 223.3331, KL Div: 15.4871\n",
      "Epoch[74/80], Step [200/600], Reconst Loss: 225.4714, KL Div: 14.6913\n",
      "Epoch[74/80], Step [250/600], Reconst Loss: 219.8764, KL Div: 15.6131\n",
      "Epoch[74/80], Step [300/600], Reconst Loss: 241.8759, KL Div: 15.5633\n",
      "Epoch[74/80], Step [350/600], Reconst Loss: 224.3344, KL Div: 15.6895\n",
      "Epoch[74/80], Step [400/600], Reconst Loss: 218.9643, KL Div: 16.1726\n",
      "Epoch[74/80], Step [450/600], Reconst Loss: 242.1299, KL Div: 15.5111\n",
      "Epoch[74/80], Step [500/600], Reconst Loss: 222.2613, KL Div: 15.9353\n",
      "Epoch[74/80], Step [550/600], Reconst Loss: 223.3138, KL Div: 14.9918\n",
      "Epoch[74/80], Step [600/600], Reconst Loss: 222.6270, KL Div: 15.9443\n",
      "Epoch[75/80], Step [50/600], Reconst Loss: 229.6853, KL Div: 15.0223\n",
      "Epoch[75/80], Step [100/600], Reconst Loss: 216.0548, KL Div: 15.6007\n",
      "Epoch[75/80], Step [150/600], Reconst Loss: 225.0896, KL Div: 15.3033\n",
      "Epoch[75/80], Step [200/600], Reconst Loss: 224.4129, KL Div: 15.9973\n",
      "Epoch[75/80], Step [250/600], Reconst Loss: 229.2776, KL Div: 15.4810\n",
      "Epoch[75/80], Step [300/600], Reconst Loss: 228.8792, KL Div: 15.0729\n",
      "Epoch[75/80], Step [350/600], Reconst Loss: 214.2108, KL Div: 15.4845\n",
      "Epoch[75/80], Step [400/600], Reconst Loss: 217.0311, KL Div: 15.2981\n",
      "Epoch[75/80], Step [450/600], Reconst Loss: 217.2959, KL Div: 14.8832\n",
      "Epoch[75/80], Step [500/600], Reconst Loss: 229.4018, KL Div: 15.8556\n",
      "Epoch[75/80], Step [550/600], Reconst Loss: 216.3326, KL Div: 16.1206\n",
      "Epoch[75/80], Step [600/600], Reconst Loss: 220.1465, KL Div: 15.1925\n",
      "Epoch[76/80], Step [50/600], Reconst Loss: 229.4978, KL Div: 15.0517\n",
      "Epoch[76/80], Step [100/600], Reconst Loss: 229.0839, KL Div: 15.2682\n",
      "Epoch[76/80], Step [150/600], Reconst Loss: 230.3670, KL Div: 15.1931\n",
      "Epoch[76/80], Step [200/600], Reconst Loss: 229.8785, KL Div: 15.7729\n",
      "Epoch[76/80], Step [250/600], Reconst Loss: 212.8604, KL Div: 15.4625\n",
      "Epoch[76/80], Step [300/600], Reconst Loss: 232.4063, KL Div: 15.8085\n",
      "Epoch[76/80], Step [350/600], Reconst Loss: 222.4682, KL Div: 15.4841\n",
      "Epoch[76/80], Step [400/600], Reconst Loss: 215.5039, KL Div: 15.5562\n",
      "Epoch[76/80], Step [450/600], Reconst Loss: 220.3744, KL Div: 15.3147\n",
      "Epoch[76/80], Step [500/600], Reconst Loss: 237.1184, KL Div: 14.5872\n",
      "Epoch[76/80], Step [550/600], Reconst Loss: 229.2476, KL Div: 15.1777\n",
      "Epoch[76/80], Step [600/600], Reconst Loss: 218.8340, KL Div: 16.1332\n",
      "Epoch[77/80], Step [50/600], Reconst Loss: 219.2884, KL Div: 15.3078\n",
      "Epoch[77/80], Step [100/600], Reconst Loss: 222.5731, KL Div: 15.7177\n",
      "Epoch[77/80], Step [150/600], Reconst Loss: 222.7210, KL Div: 14.6827\n",
      "Epoch[77/80], Step [200/600], Reconst Loss: 228.9256, KL Div: 15.0198\n",
      "Epoch[77/80], Step [250/600], Reconst Loss: 223.0634, KL Div: 15.8421\n",
      "Epoch[77/80], Step [300/600], Reconst Loss: 234.4320, KL Div: 15.0221\n",
      "Epoch[77/80], Step [350/600], Reconst Loss: 227.0240, KL Div: 14.7965\n",
      "Epoch[77/80], Step [400/600], Reconst Loss: 232.8858, KL Div: 15.3396\n",
      "Epoch[77/80], Step [450/600], Reconst Loss: 218.8080, KL Div: 14.9328\n",
      "Epoch[77/80], Step [500/600], Reconst Loss: 224.2427, KL Div: 15.3682\n",
      "Epoch[77/80], Step [550/600], Reconst Loss: 233.9936, KL Div: 15.7962\n",
      "Epoch[77/80], Step [600/600], Reconst Loss: 233.6340, KL Div: 15.7769\n",
      "Epoch[78/80], Step [50/600], Reconst Loss: 229.8286, KL Div: 15.9284\n",
      "Epoch[78/80], Step [100/600], Reconst Loss: 227.9338, KL Div: 15.1843\n",
      "Epoch[78/80], Step [150/600], Reconst Loss: 225.1372, KL Div: 15.2727\n",
      "Epoch[78/80], Step [200/600], Reconst Loss: 239.5904, KL Div: 15.4992\n",
      "Epoch[78/80], Step [250/600], Reconst Loss: 225.1450, KL Div: 15.3192\n",
      "Epoch[78/80], Step [300/600], Reconst Loss: 223.9264, KL Div: 15.5387\n",
      "Epoch[78/80], Step [350/600], Reconst Loss: 216.7151, KL Div: 15.3644\n",
      "Epoch[78/80], Step [400/600], Reconst Loss: 217.7732, KL Div: 14.9770\n",
      "Epoch[78/80], Step [450/600], Reconst Loss: 211.6009, KL Div: 15.7828\n",
      "Epoch[78/80], Step [500/600], Reconst Loss: 231.4576, KL Div: 15.1274\n",
      "Epoch[78/80], Step [550/600], Reconst Loss: 222.0181, KL Div: 15.5213\n",
      "Epoch[78/80], Step [600/600], Reconst Loss: 219.0635, KL Div: 15.3051\n",
      "Epoch[79/80], Step [50/600], Reconst Loss: 227.6149, KL Div: 15.4300\n",
      "Epoch[79/80], Step [100/600], Reconst Loss: 225.8470, KL Div: 14.7794\n",
      "Epoch[79/80], Step [150/600], Reconst Loss: 226.5475, KL Div: 15.2228\n",
      "Epoch[79/80], Step [200/600], Reconst Loss: 217.5834, KL Div: 15.4992\n",
      "Epoch[79/80], Step [250/600], Reconst Loss: 224.3540, KL Div: 15.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[79/80], Step [300/600], Reconst Loss: 224.8697, KL Div: 15.7195\n",
      "Epoch[79/80], Step [350/600], Reconst Loss: 237.1901, KL Div: 16.1994\n",
      "Epoch[79/80], Step [400/600], Reconst Loss: 214.4866, KL Div: 15.0840\n",
      "Epoch[79/80], Step [450/600], Reconst Loss: 226.6395, KL Div: 15.5873\n",
      "Epoch[79/80], Step [500/600], Reconst Loss: 220.9902, KL Div: 15.1013\n",
      "Epoch[79/80], Step [550/600], Reconst Loss: 228.2453, KL Div: 16.0226\n",
      "Epoch[79/80], Step [600/600], Reconst Loss: 227.3730, KL Div: 15.9242\n",
      "Epoch[80/80], Step [50/600], Reconst Loss: 220.4270, KL Div: 15.7162\n",
      "Epoch[80/80], Step [100/600], Reconst Loss: 221.9150, KL Div: 15.4102\n",
      "Epoch[80/80], Step [150/600], Reconst Loss: 218.8242, KL Div: 15.8331\n",
      "Epoch[80/80], Step [200/600], Reconst Loss: 238.7164, KL Div: 15.4126\n",
      "Epoch[80/80], Step [250/600], Reconst Loss: 231.0200, KL Div: 15.5817\n",
      "Epoch[80/80], Step [300/600], Reconst Loss: 214.9100, KL Div: 15.2734\n",
      "Epoch[80/80], Step [350/600], Reconst Loss: 228.7933, KL Div: 15.4659\n",
      "Epoch[80/80], Step [400/600], Reconst Loss: 216.2916, KL Div: 16.0047\n",
      "Epoch[80/80], Step [450/600], Reconst Loss: 234.1971, KL Div: 15.0909\n",
      "Epoch[80/80], Step [500/600], Reconst Loss: 228.5214, KL Div: 14.9447\n",
      "Epoch[80/80], Step [550/600], Reconst Loss: 229.2088, KL Div: 15.1102\n",
      "Epoch[80/80], Step [600/600], Reconst Loss: 227.5914, KL Div: 15.3496\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "dataset = dataset.shuffle(batch_size * 5).batch(batch_size)\n",
    "\n",
    "num_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for step, x in enumerate(dataset):\n",
    "\n",
    "        x = tf.reshape(x, [-1, image_size])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Forward pass\n",
    "            x_reconstruction_logits, mu, log_var = model(x)\n",
    "\n",
    "            # Compute reconstruction loss and kl divergence\n",
    "            reconstruction_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=x_reconstruction_logits)\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss) / batch_size\n",
    "            kl_div = - 0.5 * tf.reduce_sum(1. + log_var - tf.square(mu) - tf.exp(log_var), axis=-1)\n",
    "            kl_div = tf.reduce_mean(kl_div)\n",
    "\n",
    "            # Backprop and optimize\n",
    "            loss = tf.reduce_mean(reconstruction_loss) + kl_div\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        for g in gradients:\n",
    "            tf.clip_by_norm(g, 15)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if (step + 1) % 50 == 0:\n",
    "            print(\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
    "                  .format(epoch + 1, num_epochs, step + 1, num_batches, float(reconstruction_loss), float(kl_div)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.random.normal((batch_size, latent_dim))\n",
    "out = model.decode(z)  # decode with sigmoid\n",
    "out = tf.reshape(out, [-1, 28, 28]).numpy() * 255\n",
    "out = out.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "number = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for index in range(number):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, number, index + 1)\n",
    "    plt.imshow(out[index], cmap='gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:new_tf]",
   "language": "python",
   "name": "conda-env-new_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
